_hive.hdfs.session.path=/tmp/hive/hive/53b42494-f97a-4cb2-bd57-d0dd37e36ea6
_hive.local.session.path=/tmp/hive/53b42494-f97a-4cb2-bd57-d0dd37e36ea6
_hive.tmp_table_space=/tmp/hive/hive/53b42494-f97a-4cb2-bd57-d0dd37e36ea6/_tmp_space.db
ambari.hive.db.schema.name=hive
atlas.cluster.name=Sandbox
atlas.hook.hive.maxThreads=1
atlas.hook.hive.minThreads=1
atlas.rest.address=http://sandbox.hortonworks.com:21000
datanucleus.autoCreateSchema=false
datanucleus.cache.level2=false
datanucleus.cache.level2.type=none
datanucleus.connectionPoolingType=BONECP
datanucleus.fixedDatastore=true
datanucleus.identifierFactory=datanucleus1
datanucleus.plugin.pluginRegistryBundleCheck=LOG
datanucleus.rdbms.initializeColumnInfo=NONE
datanucleus.rdbms.useLegacyNativeValueStrategy=true
datanucleus.schema.autoCreateAll=false
datanucleus.schema.validateColumns=false
datanucleus.schema.validateConstraints=false
datanucleus.schema.validateTables=false
datanucleus.storeManagerType=rdbms
datanucleus.transactionIsolation=read-committed
dfs.balancer.block-move.timeout=0
dfs.balancer.max-no-move-interval=60000
dfs.block.access.key.update.interval=600
dfs.block.access.token.enable=true
dfs.block.access.token.lifetime=600
dfs.block.scanner.volume.bytes.per.second=1048576
dfs.blockreport.initialDelay=120
dfs.blockreport.intervalMsec=21600000
dfs.blockreport.split.threshold=1000000
dfs.blocksize=134217728
dfs.bytes-per-checksum=512
dfs.cachereport.intervalMsec=10000
dfs.client-write-packet-size=65536
dfs.client.block.write.replace-datanode-on-failure.best-effort=false
dfs.client.block.write.replace-datanode-on-failure.enable=true
dfs.client.block.write.replace-datanode-on-failure.policy=DEFAULT
dfs.client.block.write.retries=3
dfs.client.cached.conn.retry=3
dfs.client.context=default
dfs.client.datanode-restart.timeout=30
dfs.client.domain.socket.data.traffic=false
dfs.client.failover.connection.retries=0
dfs.client.failover.connection.retries.on.timeouts=0
dfs.client.failover.max.attempts=15
dfs.client.failover.sleep.base.millis=500
dfs.client.failover.sleep.max.millis=15000
dfs.client.file-block-storage-locations.num-threads=10
dfs.client.file-block-storage-locations.timeout.millis=1000
dfs.client.https.keystore.resource=ssl-client.xml
dfs.client.https.need-auth=false
dfs.client.mmap.cache.size=256
dfs.client.mmap.cache.timeout.ms=3600000
dfs.client.mmap.enabled=true
dfs.client.mmap.retry.timeout.ms=300000
dfs.client.read.shortcircuit=true
dfs.client.read.shortcircuit.skip.checksum=false
dfs.client.read.shortcircuit.streams.cache.expiry.ms=300000
dfs.client.read.shortcircuit.streams.cache.size=4096
dfs.client.retry.policy.enabled=false
dfs.client.short.circuit.replica.stale.threshold.ms=1800000
dfs.client.slow.io.warning.threshold.ms=30000
dfs.client.socket.send.buffer.size=131072
dfs.client.use.datanode.hostname=false
dfs.client.use.legacy.blockreader.local=false
dfs.client.write.exclude.nodes.cache.expiry.interval.millis=600000
dfs.cluster.administrators= hdfs
dfs.content-summary.limit=5000
dfs.datanode.address=0.0.0.0:1019
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction=0.75f
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold=10737418240
dfs.datanode.balance.bandwidthPerSec=6250000
dfs.datanode.block-pinning.enabled=false
dfs.datanode.block.id.layout.upgrade.threads=12
dfs.datanode.bp-ready.timeout=20
dfs.datanode.cache.revocation.polling.ms=500
dfs.datanode.cache.revocation.timeout.ms=900000
dfs.datanode.cached-dfsused.check.interval.ms=600000
dfs.datanode.data.dir=/hadoop/hdfs/data
dfs.datanode.data.dir.perm=750
dfs.datanode.directoryscan.interval=21600
dfs.datanode.directoryscan.threads=1
dfs.datanode.disk.check.min.gap=15m
dfs.datanode.disk.check.timeout=10m
dfs.datanode.dns.interface=default
dfs.datanode.dns.nameserver=default
dfs.datanode.drop.cache.behind.reads=false
dfs.datanode.drop.cache.behind.writes=false
dfs.datanode.du.reserved=1073741824
dfs.datanode.failed.volumes.tolerated=0
dfs.datanode.fsdatasetcache.max.threads.per.volume=4
dfs.datanode.handler.count=10
dfs.datanode.hdfs-blocks-metadata.enabled=false
dfs.datanode.http.address=0.0.0.0:1022
dfs.datanode.https.address=0.0.0.0:50475
dfs.datanode.ipc.address=0.0.0.0:8010
dfs.datanode.kerberos.principal=dn/_HOST@HDP.LOCALDOMAIN
dfs.datanode.keytab.file=/etc/security/keytabs/dn.service.keytab
dfs.datanode.max.locked.memory=0
dfs.datanode.max.transfer.threads=16384
dfs.datanode.outliers.report.interval=1800000
dfs.datanode.peer.stats.enabled=false
dfs.datanode.readahead.bytes=4194304
dfs.datanode.scan.period.hours=504
dfs.datanode.shared.file.descriptor.paths=/dev/shm,/tmp
dfs.datanode.slow.io.warning.threshold.ms=300
dfs.datanode.sync.behind.writes=false
dfs.datanode.transfer.socket.recv.buffer.size=131072
dfs.datanode.transfer.socket.send.buffer.size=131072
dfs.datanode.use.datanode.hostname=false
dfs.default.chunk.view.size=32768
dfs.domain.socket.path=/var/lib/hadoop-hdfs/dn_socket
dfs.encrypt.data.transfer=true
dfs.encrypt.data.transfer.algorithm=3des
dfs.encrypt.data.transfer.cipher.key.bitlength=128
dfs.encrypt.data.transfer.cipher.suites=AES/CTR/NoPadding
dfs.encryption.key.provider.uri=kms://http@sandbox.hortonworks.com:9292/kms
dfs.ha.automatic-failover.enabled=false
dfs.ha.fencing.ssh.connect-timeout=30000
dfs.ha.log-roll.period=120
dfs.ha.tail-edits.period=60
dfs.ha.tail-edits.rolledits.timeout=60
dfs.ha.zkfc.nn.http.timeout.ms=20000
dfs.heartbeat.interval=3
dfs.hosts.exclude=/etc/hadoop/conf/dfs.exclude
dfs.http.policy=HTTP_AND_HTTPS
dfs.https.port=50470
dfs.https.server.keystore.resource=ssl-server.xml
dfs.image.compress=false
dfs.image.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
dfs.image.transfer.bandwidthPerSec=0
dfs.image.transfer.chunksize=65536
dfs.image.transfer.timeout=60000
dfs.journalnode.edits.dir=/hadoop/hdfs/journalnode
dfs.journalnode.http-address=0.0.0.0:8480
dfs.journalnode.https-address=0.0.0.0:8481
dfs.journalnode.rpc-address=0.0.0.0:8485
dfs.mover.max-no-move-interval=60000
dfs.namenode.accesstime.precision=0
dfs.namenode.acls.enabled=false
dfs.namenode.audit.log.async=true
dfs.namenode.audit.loggers=default
dfs.namenode.avoid.read.stale.datanode=true
dfs.namenode.avoid.write.stale.datanode=true
dfs.namenode.backup.address=0.0.0.0:50100
dfs.namenode.backup.http-address=0.0.0.0:50105
dfs.namenode.block-placement-policy.default.prefer-local-node=true
dfs.namenode.blocks.per.postponedblocks.rescan=10000
dfs.namenode.checkpoint.check.period=60
dfs.namenode.checkpoint.dir=/hadoop/hdfs/namesecondary
dfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir}
dfs.namenode.checkpoint.max-retries=3
dfs.namenode.checkpoint.period=21600
dfs.namenode.checkpoint.txns=1000000
dfs.namenode.datanode.registration.ip-hostname-check=true
dfs.namenode.decommission.blocks.per.interval=500000
dfs.namenode.decommission.interval=30
dfs.namenode.decommission.max.concurrent.tracked.nodes=100
dfs.namenode.delegation.key.update-interval=86400000
dfs.namenode.delegation.token.max-lifetime=604800000
dfs.namenode.delegation.token.renew-interval=86400000
dfs.namenode.edit.log.autoroll.check.interval.ms=300000
dfs.namenode.edit.log.autoroll.multiplier.threshold=2.0
dfs.namenode.edits.dir=${dfs.namenode.name.dir}
dfs.namenode.edits.journal-plugin.qjournal=org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager
dfs.namenode.edits.noeditlogchannelflush=false
dfs.namenode.enable.retrycache=true
dfs.namenode.fs-limits.max-blocks-per-file=1048576
dfs.namenode.fs-limits.max-component-length=255
dfs.namenode.fs-limits.max-directory-items=1048576
dfs.namenode.fs-limits.max-xattr-size=16384
dfs.namenode.fs-limits.max-xattrs-per-inode=32
dfs.namenode.fs-limits.min-block-size=1048576
dfs.namenode.fslock.fair=false
dfs.namenode.full.block.report.lease.length.ms=300000
dfs.namenode.handler.count=25
dfs.namenode.heartbeat.recheck-interval=300000
dfs.namenode.http-address=sandbox.hortonworks.com:50070
dfs.namenode.https-address=sandbox.hortonworks.com:50470
dfs.namenode.inode.attributes.provider.class=org.apache.ranger.authorization.hadoop.RangerHdfsAuthorizer
dfs.namenode.inotify.max.events.per.rpc=1000
dfs.namenode.invalidate.work.pct.per.iteration=0.32f
dfs.namenode.kerberos.internal.spnego.principal=HTTP/_HOST@HDP.LOCALDOMAIN
dfs.namenode.kerberos.principal=nn/_HOST@HDP.LOCALDOMAIN
dfs.namenode.kerberos.principal.pattern=*
dfs.namenode.keytab.file=/etc/security/keytabs/nn.service.keytab
dfs.namenode.lazypersist.file.scrub.interval.sec=300
dfs.namenode.lifeline.handler.ratio=0.10
dfs.namenode.list.cache.directives.num.responses=100
dfs.namenode.list.cache.pools.num.responses=100
dfs.namenode.list.encryption.zones.num.responses=100
dfs.namenode.max.extra.edits.segments.retained=10000
dfs.namenode.max.full.block.report.leases=6
dfs.namenode.max.objects=0
dfs.namenode.metrics.logger.period.seconds=600
dfs.namenode.name.dir=/hadoop/hdfs/namenode
dfs.namenode.name.dir.restore=true
dfs.namenode.num.checkpoints.retained=2
dfs.namenode.num.extra.edits.retained=1000000
dfs.namenode.path.based.cache.block.map.allocation.percent=0.25
dfs.namenode.path.based.cache.refresh.interval.ms=30000
dfs.namenode.path.based.cache.retry.interval.ms=30000
dfs.namenode.read-lock-reporting-threshold-ms=5000
dfs.namenode.reject-unresolved-dn-topology-mapping=false
dfs.namenode.replication.considerLoad=true
dfs.namenode.replication.interval=3
dfs.namenode.replication.min=1
dfs.namenode.replication.work.multiplier.per.iteration=2
dfs.namenode.resource.check.interval=5000
dfs.namenode.resource.checked.volumes.minimum=1
dfs.namenode.resource.du.reserved=104857600
dfs.namenode.retrycache.expirytime.millis=600000
dfs.namenode.retrycache.heap.percent=0.03f
dfs.namenode.rpc-address=sandbox.hortonworks.com:8020
dfs.namenode.safemode.extension=30000
dfs.namenode.safemode.min.datanodes=0
dfs.namenode.safemode.threshold-pct=1
dfs.namenode.secondary.http-address=sandbox.hortonworks.com:50090
dfs.namenode.secondary.https-address=0.0.0.0:50091
dfs.namenode.stale.datanode.interval=30000
dfs.namenode.startup.delay.block.deletion.sec=3600
dfs.namenode.support.allow.format=true
dfs.namenode.top.enabled=true
dfs.namenode.top.num.users=10
dfs.namenode.top.window.num.buckets=10
dfs.namenode.top.windows.minutes=1,5,25
dfs.namenode.write-lock-reporting-threshold-ms=1000
dfs.namenode.write.stale.datanode.ratio=1.0f
dfs.namenode.xattrs.enabled=true
dfs.permissions.enabled=true
dfs.permissions.superusergroup=hdfs
dfs.replication=1
dfs.replication.max=50
dfs.secondary.namenode.kerberos.internal.spnego.principal=HTTP/_HOST@HDP.LOCALDOMAIN
dfs.secondary.namenode.kerberos.principal=nn/_HOST@HDP.LOCALDOMAIN
dfs.secondary.namenode.keytab.file=/etc/security/keytabs/nn.service.keytab
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms=60000
dfs.storage.policy.enabled=true
dfs.stream-buffer-size=4096
dfs.support.append=true
dfs.user.home.dir.prefix=/user
dfs.web.authentication.kerberos.keytab=/etc/security/keytabs/spnego.service.keytab
dfs.web.authentication.kerberos.principal=HTTP/_HOST@HDP.LOCALDOMAIN
dfs.webhdfs.enabled=true
dfs.webhdfs.rest-csrf.browser-useragents-regex=^Mozilla.*,^Opera.*
dfs.webhdfs.rest-csrf.custom-header=X-XSRF-HEADER
dfs.webhdfs.rest-csrf.enabled=false
dfs.webhdfs.rest-csrf.methods-to-ignore=GET,OPTIONS,HEAD,TRACE
dfs.webhdfs.ugi.expire.after.access=600000
dfs.webhdfs.user.provider.user.pattern=^[A-Za-z_][A-Za-z0-9._-]*[$]?$
dfs.xframe.enabled=true
dfs.xframe.value=SAMEORIGIN
file.blocksize=67108864
file.bytes-per-checksum=512
file.client-write-packet-size=65536
file.replication=1
file.stream-buffer-size=4096
fs.AbstractFileSystem.adl.impl=org.apache.hadoop.fs.adl.Adl
fs.AbstractFileSystem.file.impl=org.apache.hadoop.fs.local.LocalFs
fs.AbstractFileSystem.ftp.impl=org.apache.hadoop.fs.ftp.FtpFs
fs.AbstractFileSystem.har.impl=org.apache.hadoop.fs.HarFs
fs.AbstractFileSystem.hdfs.impl=org.apache.hadoop.fs.Hdfs
fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.s3a.S3A
fs.AbstractFileSystem.swebhdfs.impl=org.apache.hadoop.fs.SWebHdfs
fs.AbstractFileSystem.viewfs.impl=org.apache.hadoop.fs.viewfs.ViewFs
fs.AbstractFileSystem.webhdfs.impl=org.apache.hadoop.fs.WebHdfs
fs.adl.impl=org.apache.hadoop.fs.adl.AdlFileSystem
fs.automatic.close=true
fs.azure.authorization=false
fs.azure.local.sas.key.mode=false
fs.azure.sas.expiry.period=90d
fs.azure.secure.mode=false
fs.client.resolve.remote.symlinks=true
fs.defaultFS=hdfs://sandbox.hortonworks.com:8020
fs.df.interval=60000
fs.du.interval=600000
fs.ftp.host=0.0.0.0
fs.ftp.host.port=21
fs.har.impl=org.apache.hadoop.hive.shims.HiveHarFileSystem
fs.har.impl.disable.cache=true
fs.permissions.umask-mode=022
fs.s3.block.size=67108864
fs.s3.buffer.dir=${hadoop.tmp.dir}/s3
fs.s3.maxRetries=4
fs.s3.sleepTimeSeconds=10
fs.s3a.attempts.maximum=20
fs.s3a.block.size=32M
fs.s3a.buffer.dir=${hadoop.tmp.dir}/s3a
fs.s3a.connection.establish.timeout=5000
fs.s3a.connection.maximum=15
fs.s3a.connection.ssl.enabled=true
fs.s3a.connection.timeout=200000
fs.s3a.fast.upload=false
fs.s3a.fast.upload.active.blocks=4
fs.s3a.fast.upload.buffer=disk
fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
fs.s3a.max.total.tasks=5
fs.s3a.multiobjectdelete.enable=true
fs.s3a.multipart.purge=false
fs.s3a.multipart.purge.age=86400
fs.s3a.multipart.size=100M
fs.s3a.multipart.threshold=2147483647
fs.s3a.paging.maximum=5000
fs.s3a.path.style.access=false
fs.s3a.readahead.range=64K
fs.s3a.socket.recv.buffer=8192
fs.s3a.socket.send.buffer=8192
fs.s3a.threads.keepalivetime=60
fs.s3a.threads.max=10
fs.s3n.block.size=67108864
fs.s3n.multipart.copy.block.size=5368709120
fs.s3n.multipart.uploads.block.size=67108864
fs.s3n.multipart.uploads.enabled=false
fs.scheme.class=dfs
fs.swift.impl=org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
fs.trash.checkpoint.interval=0
fs.trash.interval=360
ftp.blocksize=67108864
ftp.bytes-per-checksum=512
ftp.client-write-packet-size=65536
ftp.replication=3
ftp.stream-buffer-size=4096
ha.failover-controller.active-standby-elector.zk.op.retries=120
ha.failover-controller.cli-check.rpc-timeout.ms=20000
ha.failover-controller.graceful-fence.connection.retries=1
ha.failover-controller.graceful-fence.rpc-timeout.ms=5000
ha.failover-controller.new-active.rpc-timeout.ms=60000
ha.health-monitor.check-interval.ms=1000
ha.health-monitor.connect-retry-interval.ms=1000
ha.health-monitor.rpc-timeout.ms=45000
ha.health-monitor.sleep-after-disconnect.ms=1000
ha.zookeeper.acl=sasl:nn:rwcda
ha.zookeeper.parent-znode=/hadoop-ha
ha.zookeeper.session-timeout.ms=5000
hadoop.bin.path=/usr/hdp/2.6.0.3-8/hadoop/bin/hadoop
hadoop.common.configuration.version=0.23.0
hadoop.fuse.connection.timeout=300
hadoop.fuse.timer.period=5
hadoop.hdfs.configuration.version=1
hadoop.http.authentication.cookie.domain=hortonworks.com
hadoop.http.authentication.kerberos.keytab=/etc/security/keytabs/spnego.service.keytab
hadoop.http.authentication.kerberos.principal=HTTP/_HOST@UBUNTU
hadoop.http.authentication.signature.secret.file=/etc/security/http_secret
hadoop.http.authentication.simple.anonymous.allowed=true
hadoop.http.authentication.token.validity=36000
hadoop.http.authentication.type=simple
hadoop.http.cross-origin.allowed-headers=X-Requested-With,Content-Type,Accept,Origin
hadoop.http.cross-origin.allowed-methods=GET,POST,HEAD
hadoop.http.cross-origin.allowed-origins=*
hadoop.http.cross-origin.enabled=false
hadoop.http.cross-origin.max-age=1800
hadoop.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer
hadoop.http.staticuser.user=dr.who
hadoop.jetty.logs.serve.aliases=true
hadoop.kerberos.kinit.command=kinit
hadoop.kerberos.min.seconds.before.relogin=60
hadoop.proxyuser.HTTP.groups=users
hadoop.proxyuser.HTTP.hosts=*\\,sandbox.hortonworks.com
hadoop.proxyuser.ambari-server-sandbox.groups=*
hadoop.proxyuser.ambari-server-sandbox.hosts=*
hadoop.proxyuser.falcon.groups=*
hadoop.proxyuser.falcon.hosts=*
hadoop.proxyuser.hbase.groups=*
hadoop.proxyuser.hbase.hosts=*
hadoop.proxyuser.hcat.groups=*
hadoop.proxyuser.hcat.hosts=sandbox.hortonworks.com
hadoop.proxyuser.hdfs.groups=*
hadoop.proxyuser.hdfs.hosts=*
hadoop.proxyuser.hive.groups=*
hadoop.proxyuser.hive.hosts=sandbox.hortonworks.com
hadoop.proxyuser.hue.groups=*
hadoop.proxyuser.hue.hosts=*
hadoop.proxyuser.kms.groups=*
hadoop.proxyuser.knox.groups=users
hadoop.proxyuser.knox.hosts=sandbox.hortonworks.com
hadoop.proxyuser.livy.groups=*
hadoop.proxyuser.livy.hosts=*
hadoop.proxyuser.oozie.groups=*
hadoop.proxyuser.oozie.hosts=sandbox.hortonworks.com
hadoop.proxyuser.yarn.groups=*
hadoop.proxyuser.yarn.hosts=sandbox.hortonworks.com
hadoop.proxyuser.zeppelin-sandbox.groups=*
hadoop.proxyuser.zeppelin-sandbox.hosts=*
hadoop.proxyuser.zeppelin.groups=*
hadoop.proxyuser.zeppelin.hosts=*
hadoop.registry.client.auth=kerberos
hadoop.registry.jaas.context=Client
hadoop.registry.rm.enabled=true
hadoop.registry.secure=true
hadoop.registry.system.accounts=sasl:yarn,sasl:mapred,sasl:hadoop,sasl:hdfs,sasl:rm,sasl:hive
hadoop.registry.system.acls=sasl:yarn@, sasl:mapred@, sasl:hdfs@
hadoop.registry.zk.connection.timeout.ms=15000
hadoop.registry.zk.quorum=sandbox.hortonworks.com:2181
hadoop.registry.zk.retry.ceiling.ms=60000
hadoop.registry.zk.retry.interval.ms=1000
hadoop.registry.zk.retry.times=5
hadoop.registry.zk.root=/registry
hadoop.registry.zk.session.timeout.ms=60000
hadoop.rpc.protection=privacy
hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory
hadoop.security.auth_to_local=RULE:[1:$1@$0](ambari-qa-sandbox@HDP.LOCALDOMAIN)s/.*/ambari-qa/
RULE:[1:$1@$0](hbase-sandbox@HDP.LOCALDOMAIN)s/.*/hbase/
RULE:[1:$1@$0](hdfs-sandbox@HDP.LOCALDOMAIN)s/.*/hdfs/
RULE:[1:$1@$0](spark-sandbox@HDP.LOCALDOMAIN)s/.*/spark/
RULE:[1:$1@$0](zeppelin-sandbox@HDP.LOCALDOMAIN)s/.*/zeppelin/
RULE:[1:$1@$0](.*@HDP.LOCALDOMAIN)s/@.*///L
RULE:[2:$1@$0](amshbase@HDP.LOCALDOMAIN)s/.*/ams/
RULE:[2:$1@$0](amszk@HDP.LOCALDOMAIN)s/.*/ams/
RULE:[2:$1@$0](atlas@HDP.LOCALDOMAIN)s/.*/atlas/
RULE:[2:$1@$0](dn@HDP.LOCALDOMAIN)s/.*/hdfs/
RULE:[2:$1@$0](falcon@HDP.LOCALDOMAIN)s/.*/falcon/
RULE:[2:$1@$0](hbase@HDP.LOCALDOMAIN)s/.*/hbase/
RULE:[2:$1@$0](hive@HDP.LOCALDOMAIN)s/.*/hive/
RULE:[2:$1@$0](jhs@HDP.LOCALDOMAIN)s/.*/mapred/
RULE:[2:$1@$0](knox@HDP.LOCALDOMAIN)s/.*/knox/
RULE:[2:$1@$0](livy@HDP.LOCALDOMAIN)s/.*/livy/
RULE:[2:$1@$0](nfs@HDP.LOCALDOMAIN)s/.*/hdfs/
RULE:[2:$1@$0](nm@HDP.LOCALDOMAIN)s/.*/yarn/
RULE:[2:$1@$0](nn@HDP.LOCALDOMAIN)s/.*/hdfs/
RULE:[2:$1@$0](oozie@HDP.LOCALDOMAIN)s/.*/oozie/
RULE:[2:$1@$0](rangeradmin@HDP.LOCALDOMAIN)s/.*/ranger/
RULE:[2:$1@$0](rangerkms@HDP.LOCALDOMAIN)s/.*/keyadmin/
RULE:[2:$1@$0](rangertagsync@HDP.LOCALDOMAIN)s/.*/rangertagsync/
RULE:[2:$1@$0](rangerusersync@HDP.LOCALDOMAIN)s/.*/rangerusersync/
RULE:[2:$1@$0](rm@HDP.LOCALDOMAIN)s/.*/yarn/
RULE:[2:$1@$0](yarn@HDP.LOCALDOMAIN)s/.*/yarn/
DEFAULT
hadoop.security.authentication=kerberos
hadoop.security.authorization=true
hadoop.security.crypto.buffer.size=8192
hadoop.security.crypto.cipher.suite=AES/CTR/NoPadding
hadoop.security.crypto.codec.classes.aes.ctr.nopadding=org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec
hadoop.security.dns.log-slow-lookups.enabled=false
hadoop.security.dns.log-slow-lookups.threshold.ms=1000
hadoop.security.group.mapping=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
hadoop.security.group.mapping.ldap.connection.timeout.ms=60000
hadoop.security.group.mapping.ldap.directory.search.timeout=10000
hadoop.security.group.mapping.ldap.posix.attr.gid.name=gidNumber
hadoop.security.group.mapping.ldap.posix.attr.uid.name=uidNumber
hadoop.security.group.mapping.ldap.read.timeout.ms=60000
hadoop.security.group.mapping.ldap.search.attr.group.name=cn
hadoop.security.group.mapping.ldap.search.attr.member=member
hadoop.security.group.mapping.ldap.search.filter.group=(objectClass=group)
hadoop.security.group.mapping.ldap.search.filter.user=(&(objectClass=user)(sAMAccountName={0}))
hadoop.security.group.mapping.ldap.search.group.hierarchy.levels=0
hadoop.security.group.mapping.ldap.ssl=false
hadoop.security.group.mapping.providers.combined=true
hadoop.security.groups.cache.background.reload=false
hadoop.security.groups.cache.background.reload.threads=3
hadoop.security.groups.cache.secs=300
hadoop.security.groups.cache.warn.after.ms=5000
hadoop.security.groups.negative-cache.secs=30
hadoop.security.instrumentation.requires.admin=false
hadoop.security.java.secure.random.algorithm=SHA1PRNG
hadoop.security.key.provider.path=kms://http@sandbox.hortonworks.com:9292/kms
hadoop.security.kms.client.authentication.retry-count=1
hadoop.security.kms.client.encrypted.key.cache.expiry=43200000
hadoop.security.kms.client.encrypted.key.cache.low-watermark=0.3f
hadoop.security.kms.client.encrypted.key.cache.num.refill.threads=2
hadoop.security.kms.client.encrypted.key.cache.size=500
hadoop.security.random.device.file.path=/dev/urandom
hadoop.security.sensitive-config-keys=password$,fs.s3.*[Ss]ecret.?[Kk]ey,fs.azure.account.key.*,dfs.webhdfs.oauth2.[a-z]+.token,hadoop.security.sensitive-config-keys
hadoop.security.uid.cache.secs=14400
hadoop.shell.missing.defaultFs.warning=false
hadoop.shell.safely.delete.limit.num.files=100
hadoop.ssl.client.conf=ssl-client.xml
hadoop.ssl.enabled=false
hadoop.ssl.enabled.protocols=TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2
hadoop.ssl.hostname.verifier=DEFAULT
hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
hadoop.ssl.require.client.cert=false
hadoop.ssl.server.conf=ssl-server.xml
hadoop.tmp.dir=/tmp/hadoop-${user.name}
hadoop.user.group.static.mapping.overrides=dr.who=;
hadoop.util.hash.type=murmur
hadoop.workaround.non.threadsafe.getpwuid=false
hive.allow.udf.load.on.demand=true
hive.analyze.stmt.collect.partlevel.stats=true
hive.archive.enabled=false
hive.auto.convert.join=true
hive.auto.convert.join.noconditionaltask=true
hive.auto.convert.join.noconditionaltask.size=1000000000
hive.auto.convert.join.use.nonstaged=false
hive.auto.convert.sortmerge.join=true
hive.auto.convert.sortmerge.join.bigtable.selection.policy=org.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ
hive.auto.convert.sortmerge.join.reduce.side=true
hive.auto.convert.sortmerge.join.to.mapjoin=false
hive.auto.progress.timeout=0s
hive.autogen.columnalias.prefix.includefuncname=false
hive.autogen.columnalias.prefix.label=_c
hive.aux.jars.path=file:///usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar
hive.binary.record.max.length=1000
hive.cache.expr.evaluation=true
hive.cbo.costmodel.cpu=0.000001
hive.cbo.costmodel.extended=false
hive.cbo.costmodel.hdfs.read=1.5
hive.cbo.costmodel.hdfs.write=10.0
hive.cbo.costmodel.local.fs.read=4.0
hive.cbo.costmodel.local.fs.write=4.0
hive.cbo.costmodel.network=150.0
hive.cbo.enable=true
hive.cbo.returnpath.hiveop=false
hive.cli.errors.ignore=false
hive.cli.pretty.output.num.cols=-1
hive.cli.print.current.db=false
hive.cli.print.header=false
hive.cli.prompt=hive
hive.cluster.delegation.token.store.class=org.apache.hadoop.hive.thrift.ZooKeeperTokenStore
hive.cluster.delegation.token.store.zookeeper.connectString=sandbox.hortonworks.com:2181
hive.cluster.delegation.token.store.zookeeper.znode=/hive/cluster/delegation
hive.compactor.abortedtxn.threshold=1000
hive.compactor.check.interval=300s
hive.compactor.cleaner.run.interval=5000ms
hive.compactor.delta.num.threshold=10
hive.compactor.delta.pct.threshold=0.1f
hive.compactor.history.reaper.interval=2m
hive.compactor.history.retention.attempted=2
hive.compactor.history.retention.failed=3
hive.compactor.history.retention.succeeded=3
hive.compactor.initiator.failed.compacts.threshold=2
hive.compactor.initiator.on=false
hive.compactor.max.num.delta=500
hive.compactor.worker.threads=0
hive.compactor.worker.timeout=86400s
hive.compat=0.12
hive.compute.query.using.stats=true
hive.compute.splits.in.am=true
hive.conf.hidden.list=javax.jdo.option.ConnectionPassword,hive.server2.keystore.password
hive.conf.restricted.list=hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role
hive.conf.validation=true
hive.convert.join.bucket.mapjoin.tez=false
hive.count.open.txns.interval=1s
hive.counters.group.name=HIVE
hive.debug.localtask=false
hive.decode.partition.name=false
hive.default.fileformat=TextFile
hive.default.fileformat.managed=TextFile
hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe
hive.default.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
hive.direct.sql.max.elements.in.clause=1000
hive.direct.sql.max.elements.values.clause=1000
hive.direct.sql.max.query.length=100
hive.display.partition.cols.separately=true
hive.downloaded.resources.dir=/tmp/${hive.session.id}_resources
hive.enforce.bucketing=false
hive.enforce.bucketmapjoin=false
hive.enforce.sorting=true
hive.enforce.sortmergebucketmapjoin=true
hive.entity.capture.transform=false
hive.entity.separator=@
hive.error.on.empty.partition=false
hive.exec.check.crossproducts=true
hive.exec.compress.intermediate=false
hive.exec.compress.output=false
hive.exec.concatenate.check.index=true
hive.exec.copyfile.maxsize=33554432
hive.exec.counters.pull.interval=1000
hive.exec.default.partition.name=__HIVE_DEFAULT_PARTITION__
hive.exec.drop.ignorenonexistent=true
hive.exec.dynamic.partition=true
hive.exec.dynamic.partition.mode=strict
hive.exec.failure.hooks=org.apache.hadoop.hive.ql.hooks.ATSHook
hive.exec.infer.bucket.sort=false
hive.exec.infer.bucket.sort.num.buckets.power.two=false
hive.exec.job.debug.capture.stacktraces=true
hive.exec.job.debug.timeout=30000
hive.exec.local.scratchdir=/tmp/hive
hive.exec.max.created.files=100000
hive.exec.max.dynamic.partitions=5000
hive.exec.max.dynamic.partitions.pernode=2000
hive.exec.mode.local.auto=false
hive.exec.mode.local.auto.input.files.max=4
hive.exec.mode.local.auto.inputbytes.max=134217728
hive.exec.orc.base.delta.ratio=8
hive.exec.orc.block.padding.tolerance=0.05
hive.exec.orc.compression.strategy=SPEED
hive.exec.orc.default.block.padding=true
hive.exec.orc.default.block.size=268435456
hive.exec.orc.default.buffer.size=262144
hive.exec.orc.default.compress=ZLIB
hive.exec.orc.default.row.index.stride=10000
hive.exec.orc.default.stripe.size=67108864
hive.exec.orc.dictionary.key.size.threshold=0.8
hive.exec.orc.encoding.strategy=SPEED
hive.exec.orc.memory.pool=0.5
hive.exec.orc.skip.corrupt.data=false
hive.exec.orc.split.strategy=HYBRID
hive.exec.orc.zerocopy=false
hive.exec.parallel=false
hive.exec.parallel.thread.number=8
hive.exec.perf.logger=org.apache.hadoop.hive.ql.log.PerfLogger
hive.exec.post.hooks=org.apache.hadoop.hive.ql.hooks.ATSHook,org.apache.atlas.hive.hook.HiveHook
hive.exec.pre.hooks=org.apache.hadoop.hive.ql.hooks.ATSHook
hive.exec.rcfile.use.explicit.header=true
hive.exec.rcfile.use.sync.cache=true
hive.exec.reducers.bytes.per.reducer=67108864
hive.exec.reducers.max=1009
hive.exec.rowoffset=false
hive.exec.schema.evolution=true
hive.exec.scratchdir=/tmp/hive
hive.exec.script.allow.partial.consumption=false
hive.exec.script.maxerrsize=100000
hive.exec.script.trust=false
hive.exec.show.job.failure.debug.info=true
hive.exec.stagingdir=.hive-staging
hive.exec.submit.local.task.via.child=true
hive.exec.submitviachild=false
hive.exec.tasklog.debug.timeout=20000
hive.exec.temporary.table.storage=default
hive.execution.engine=tez
hive.exim.strict.repl.tables=true
hive.exim.uri.scheme.whitelist=hdfs,pfile,file
hive.explain.dependency.append.tasktype=false
hive.explain.user=true
hive.fetch.output.serde=org.apache.hadoop.hive.serde2.DelimitedJSONSerDe
hive.fetch.task.aggr=false
hive.fetch.task.conversion=more
hive.fetch.task.conversion.threshold=1073741824
hive.file.max.footer=100
hive.fileformat.check=true
hive.groupby.mapaggr.checkinterval=100000
hive.groupby.orderby.position.alias=false
hive.groupby.skewindata=false
hive.hadoop.supports.splittable.combineinputformat=false
hive.hash.table.inflation.factor=2.0
hive.hashtable.initialCapacity=100000
hive.hashtable.key.count.adjustment=1.0
hive.hashtable.loadfactor=0.75
hive.hbase.generatehfiles=false
hive.hbase.snapshot.restoredir=/tmp
hive.hbase.wal.enabled=true
hive.heartbeat.interval=1000
hive.hmshandler.force.reload.conf=false
hive.hmshandler.retry.attempts=10
hive.hmshandler.retry.interval=2000ms
hive.hwi.listen.host=0.0.0.0
hive.hwi.listen.port=9999
hive.hwi.war.file=${env:HWI_WAR_FILE}
hive.ignore.mapjoin.hint=true
hive.in.test=false
hive.in.tez.test=false
hive.index.compact.binary.search=true
hive.index.compact.file.ignore.hdfs=false
hive.index.compact.query.max.entries=10000000
hive.index.compact.query.max.size=10737418240
hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
hive.insert.into.external.tables=true
hive.insert.into.multilevel.dirs=false
hive.int.timestamp.conversion.in.seconds=false
hive.internal.ss.authz.settings.applied.marker=true
hive.io.rcfile.column.number.conf=0
hive.io.rcfile.record.buffer.size=4194304
hive.io.rcfile.record.interval=2147483647
hive.io.rcfile.tolerate.corruptions=false
hive.jobname.length=50
hive.join.cache.size=25000
hive.join.emit.interval=1000
hive.lazysimple.extended_boolean_literal=false
hive.limit.optimize.enable=true
hive.limit.optimize.fetch.max=50000
hive.limit.optimize.limit.file=10
hive.limit.pushdown.memory.usage=0.04
hive.limit.query.max.table.partition=-1
hive.limit.row.max.size=100000
hive.localize.resource.num.wait.attempts=5
hive.localize.resource.wait.interval=5000ms
hive.lock.manager=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager
hive.lock.mapred.only.operation=false
hive.lock.numretries=100
hive.lock.sleep.between.retries=60s
hive.lockmgr.zookeeper.default.partition.name=__HIVE_DEFAULT_ZOOKEEPER_PARTITION__
hive.log.every.n.records=0
hive.log.explain.output=false
hive.map.aggr=true
hive.map.aggr.hash.force.flush.memory.threshold=0.9
hive.map.aggr.hash.min.reduction=0.5
hive.map.aggr.hash.percentmemory=0.5
hive.map.groupby.sorted=false
hive.map.groupby.sorted.testmode=false
hive.mapjoin.bucket.cache.size=10000
hive.mapjoin.check.memory.rows=100000
hive.mapjoin.followby.gby.localtask.max.memory.usage=0.55
hive.mapjoin.followby.map.aggr.hash.percentmemory=0.3
hive.mapjoin.hybridgrace.hashtable=true
hive.mapjoin.hybridgrace.memcheckfrequency=1024
hive.mapjoin.hybridgrace.minnumpartitions=16
hive.mapjoin.hybridgrace.minwbsize=524288
hive.mapjoin.localtask.max.memory.usage=0.9
hive.mapjoin.optimized.hashtable=true
hive.mapjoin.optimized.hashtable.probe.percent=0.5
hive.mapjoin.optimized.hashtable.wbsize=8388608
hive.mapjoin.smalltable.filesize=25000000
hive.mapper.cannot.span.multiple.partitions=false
hive.mapred.local.mem=0
hive.mapred.mode=nonstrict
hive.mapred.partitioner=org.apache.hadoop.hive.ql.io.DefaultHivePartitioner
hive.mapred.reduce.tasks.speculative.execution=false
hive.max.open.txns=100000
hive.merge.cardinality.check=true
hive.merge.mapfiles=true
hive.merge.mapredfiles=false
hive.merge.orcfile.stripe.level=true
hive.merge.rcfile.block.level=true
hive.merge.size.per.task=256000000
hive.merge.smallfiles.avgsize=16000000
hive.merge.sparkfiles=false
hive.merge.tezfiles=false
hive.metadata.move.exported.metadata.to.trash=true
hive.metastore.aggregate.stats.cache.clean.until=0.8
hive.metastore.aggregate.stats.cache.enabled=true
hive.metastore.aggregate.stats.cache.fpp=0.01
hive.metastore.aggregate.stats.cache.max.full=0.9
hive.metastore.aggregate.stats.cache.max.partitions=10000
hive.metastore.aggregate.stats.cache.max.reader.wait=1000ms
hive.metastore.aggregate.stats.cache.max.variance=0.01
hive.metastore.aggregate.stats.cache.max.writer.wait=5000ms
hive.metastore.aggregate.stats.cache.size=10000
hive.metastore.aggregate.stats.cache.ttl=600s
hive.metastore.archive.intermediate.archived=_INTERMEDIATE_ARCHIVED
hive.metastore.archive.intermediate.extracted=_INTERMEDIATE_EXTRACTED
hive.metastore.archive.intermediate.original=_INTERMEDIATE_ORIGINAL
hive.metastore.authorization.storage.check.externaltable.drop=false
hive.metastore.authorization.storage.checks=false
hive.metastore.batch.retrieve.max=300
hive.metastore.batch.retrieve.table.partition.max=1000
hive.metastore.cache.pinobjtypes=Table,Database,Type,FieldSchema,Order
hive.metastore.client.connect.retry.delay=5s
hive.metastore.client.drop.partitions.using.expressions=true
hive.metastore.client.socket.lifetime=0s
hive.metastore.client.socket.timeout=1800s
hive.metastore.connect.retries=24
hive.metastore.direct.sql.batch.size=0
hive.metastore.disallow.incompatible.col.type.changes=false
hive.metastore.dml.events=false
hive.metastore.event.clean.freq=0s
hive.metastore.event.db.listener.timetolive=86400s
hive.metastore.event.expiry.duration=0s
hive.metastore.event.message.factory=org.apache.hadoop.hive.metastore.messaging.json.JSONMessageFactory
hive.metastore.execute.setugi=true
hive.metastore.expression.proxy=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
hive.metastore.failure.retries=24
hive.metastore.filter.hook=org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
hive.metastore.fs.handler.class=org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
hive.metastore.fshandler.threads=15
hive.metastore.initial.metadata.count.enabled=true
hive.metastore.integral.jdo.pushdown=false
hive.metastore.kerberos.keytab.file=/etc/security/keytabs/hive.service.keytab
hive.metastore.kerberos.principal=hive/_HOST@HDP.LOCALDOMAIN
hive.metastore.metrics.enabled=false
hive.metastore.orm.retrieveMapNullsAsEmptyStrings=false
hive.metastore.port=9083
hive.metastore.pre.event.listeners=org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener
hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore
hive.metastore.sasl.enabled=true
hive.metastore.schema.verification=false
hive.metastore.schema.verification.record.version=false
hive.metastore.server.max.message.size=104857600
hive.metastore.server.max.threads=100000
hive.metastore.server.min.threads=200
hive.metastore.server.tcp.keepalive=true
hive.metastore.stats.ndv.densityfunction=false
hive.metastore.thrift.compact.protocol.enabled=false
hive.metastore.thrift.framed.transport.enabled=false
hive.metastore.try.direct.sql=true
hive.metastore.try.direct.sql.ddl=true
hive.metastore.txn.store.impl=org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
hive.metastore.uris=thrift://sandbox.hortonworks.com:9083
hive.metastore.warehouse.dir=/apps/hive/warehouse
hive.msck.path.validation=throw
hive.msck.repair.batch.size=0
hive.multi.insert.move.tasks.share.dependencies=false
hive.multigroupby.singlereducer=true
hive.mv.files.thread=15
hive.new.job.grouping.set.cardinality=30
hive.optimize.bucketingsorting=true
hive.optimize.bucketmapjoin=true
hive.optimize.bucketmapjoin.sortedmerge=false
hive.optimize.constant.propagation=true
hive.optimize.correlation=false
hive.optimize.distinct.rewrite=true
hive.optimize.groupby=true
hive.optimize.index.autoupdate=false
hive.optimize.index.filter=true
hive.optimize.index.filter.compact.maxsize=-1
hive.optimize.index.filter.compact.minsize=5368709120
hive.optimize.index.groupby=false
hive.optimize.listbucketing=false
hive.optimize.metadataonly=true
hive.optimize.null.scan=true
hive.optimize.partition.columns.separate=true
hive.optimize.point.lookup=true
hive.optimize.point.lookup.min=31
hive.optimize.ppd=true
hive.optimize.ppd.storage=true
hive.optimize.reducededuplication=true
hive.optimize.reducededuplication.min.reducer=4
hive.optimize.remove.identity.project=true
hive.optimize.sampling.orderby=false
hive.optimize.sampling.orderby.number=1000
hive.optimize.sampling.orderby.percent=0.1
hive.optimize.skewjoin=false
hive.optimize.skewjoin.compiletime=false
hive.optimize.sort.dynamic.partition=false
hive.optimize.union.remove=false
hive.orc.cache.stripe.details.size=10000
hive.orc.cache.use.soft.references=false
hive.orc.compute.splits.num.threads=10
hive.orc.row.index.stride.dictionary.check=true
hive.orc.splits.include.file.footer=false
hive.outerjoin.supports.filters=true
hive.parquet.timestamp.skip.conversion=true
hive.plan.serialization.format=kryo
hive.ppd.recognizetransivity=true
hive.ppd.remove.duplicatefilters=true
hive.prewarm.enabled=false
hive.prewarm.numcontainers=3
hive.query.result.fileformat=TextFile
hive.querylog.enable.plan.progress=true
hive.querylog.location=/tmp/hive
hive.querylog.plan.progress.interval=60000ms
hive.reorder.nway.joins=true
hive.repl.cm.enabled=false
hive.repl.cm.interval=3600s
hive.repl.cm.retain=24h
hive.repl.cmrootdir=/user/hive/cmroot/
hive.repl.rootdir=/user/hive/repl/
hive.repl.task.factory=org.apache.hive.hcatalog.api.repl.exim.EximReplicationTaskFactory
hive.resultset.use.unique.column.names=true
hive.rework.mapredwork=false
hive.rpc.query.plan=false
hive.sample.seednumber=0
hive.scratch.dir.permission=700
hive.scratchdir.lock=false
hive.script.auto.progress=false
hive.script.operator.env.blacklist=hive.txn.valid.txns,hive.script.operator.env.blacklist
hive.script.operator.id.env.var=HIVE_SCRIPT_OPERATOR_ID
hive.script.operator.truncate.env=false
hive.script.recordreader=org.apache.hadoop.hive.ql.exec.TextRecordReader
hive.script.recordwriter=org.apache.hadoop.hive.ql.exec.TextRecordWriter
hive.script.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator
hive.security.authorization.createtable.owner.grants=INSERT,SELECT,UPDATE,DELETE
hive.security.authorization.enabled=true
hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory
hive.security.authorization.sqlstd.confwhitelist=hive\.auto\..*|hive\.cbo\..*|hive\.convert\..*|hive\.exec\.dynamic\.partition.*|hive\.exec\.max\.dynamic\.partitions.*|hive\.exec\.compress\..*|hive\.exec\.infer\..*|hive\.exec\.mode.local\..*|hive\.exec\.orc\..*|hive\.exec\.parallel.*|hive\.explain\..*|hive\.fetch.task\..*|hive\.groupby\..*|hive\.hbase\..*|hive\.index\..*|hive\.index\..*|hive\.intermediate\..*|hive\.join\..*|hive\.limit\..*|hive\.log\..*|hive\.mapjoin\..*|hive\.merge\..*|hive\.optimize\..*|hive\.orc\..*|hive\.outerjoin\..*|hive\.parquet\..*|hive\.ppd\..*|hive\.prewarm\..*|hive\.server2\.proxy\.user|hive\.skewjoin\..*|hive\.smbjoin\..*|hive\.stats\..*|hive\.tez\..*|hive\.vectorized\..*|mapred\.map\..*|mapred\.reduce\..*|mapred\.output\.compression\.codec|mapred\.job\.queuename|mapred\.output\.compression\.type|mapred\.min\.split\.size|mapreduce\.job\.reduce\.slowstart\.completedmaps|mapreduce\.job\.queuename|mapreduce\.job\.tags|mapreduce\.input\.fileinputformat\.split\.minsize|mapreduce\.map\..*|mapreduce\.reduce\..*|mapreduce\.output\.fileoutputformat\.compress\.codec|mapreduce\.output\.fileoutputformat\.compress\.type|oozie\..*|tez\.am\..*|tez\.task\..*|tez\.runtime\..*|tez\.queue\.name|hive\.exec\.reducers\.bytes\.per\.reducer|hive\.client\.stats\.counters|hive\.exec\.default\.partition\.name|hive\.exec\.drop\.ignorenonexistent|hive\.counters\.group\.name|hive\.default\.fileformat\.managed|hive\.enforce\.bucketing|hive\.enforce\.bucketmapjoin|hive\.enforce\.sorting|hive\.enforce\.sortmergebucketmapjoin|hive\.cache\.expr\.evaluation|hive\.hashtable\.loadfactor|hive\.hashtable\.initialCapacity|hive\.ignore\.mapjoin\.hint|hive\.limit\.row\.max\.size|hive\.mapred\.mode|hive\.map\.aggr|hive\.compute\.query\.using\.stats|hive\.exec\.rowoffset|hive\.variable\.substitute|hive\.variable\.substitute\.depth|hive\.autogen\.columnalias\.prefix\.includefuncname|hive\.autogen\.columnalias\.prefix\.label|hive\.exec\.check\.crossproducts|hive\.compat|hive\.exec\.concatenate\.check\.index|hive\.display\.partition\.cols\.separately|hive\.error\.on\.empty\.partition|hive\.execution\.engine|hive\.exec\.copyfile\.maxsize|hive\.exim\.uri\.scheme\.whitelist|hive\.file\.max\.footer|hive\.insert\.into\.multilevel\.dirs|hive\.localize\.resource\.num\.wait\.attempts|hive\.multi\.insert\.move\.tasks\.share\.dependencies|hive\.support\.quoted\.identifiers|hive\.resultset\.use\.unique\.column\.names|hive\.analyze\.stmt\.collect\.partlevel\.stats|hive\.server2\.logging\.operation\.level|hive\.support\.sql11\.reserved\.keywords|hive\.exec\.job\.debug\.capture\.stacktraces|hive\.exec\.job\.debug\.timeout|hive\.exec\.max\.created\.files|hive\.exec\.reducers\.max|hive\.reorder\.nway\.joins|hive\.output\.file\.extension|hive\.exec\.show\.job\.failure\.debug\.info|hive\.exec\.tasklog\.debug\.timeout
hive.security.authorization.task.factory=org.apache.hadoop.hive.ql.parse.authorization.HiveAuthorizationTaskFactoryImpl
hive.security.command.whitelist=set,reset,dfs,add,list,delete,reload,compile
hive.security.metastore.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
hive.security.metastore.authorization.auth.reads=true
hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
hive.serdes.using.metastore.for.schema=org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
hive.server.read.socket.timeout=10s
hive.server.tcp.keepalive=true
hive.server2.allow.user.substitution=true
hive.server2.async.exec.keepalive.time=10s
hive.server2.async.exec.shutdown.timeout=10s
hive.server2.async.exec.threads=100
hive.server2.async.exec.wait.queue.size=100
hive.server2.authentication=KERBEROS
hive.server2.authentication.kerberos.keytab=/etc/security/keytabs/hive.service.keytab
hive.server2.authentication.kerberos.principal=hive/_HOST@HDP.LOCALDOMAIN
hive.server2.authentication.ldap.groupClassKey=groupOfNames
hive.server2.authentication.ldap.groupMembershipKey=member
hive.server2.authentication.ldap.guidKey=uid
hive.server2.authentication.spnego.keytab=/etc/security/keytabs/spnego.service.keytab
hive.server2.authentication.spnego.principal=HTTP/_HOST@HDP.LOCALDOMAIN
hive.server2.clear.dangling.scratchdir=false
hive.server2.clear.dangling.scratchdir.interval=1800s
hive.server2.enable.doAs=false
hive.server2.global.init.file.location=/usr/hdp/current/hive-client/conf
hive.server2.idle.operation.timeout=5d
hive.server2.idle.session.check.operation=true
hive.server2.idle.session.timeout=7d
hive.server2.in.place.progress=true
hive.server2.keystore.path=/etc/security/serverKeys/server.keystore.jks
hive.server2.logging.operation.enabled=true
hive.server2.logging.operation.level=EXECUTION
hive.server2.logging.operation.log.location=/tmp/hive/operation_logs
hive.server2.long.polling.timeout=5000ms
hive.server2.map.fair.scheduler.queue=true
hive.server2.max.start.attempts=5
hive.server2.metrics.enabled=false
hive.server2.parallel.ops.in.session=false
hive.server2.session.check.interval=6h
hive.server2.support.dynamic.service.discovery=true
hive.server2.table.type.mapping=CLASSIC
hive.server2.tez.default.queues=default
hive.server2.tez.initialize.default.sessions=false
hive.server2.tez.sessions.per.default.queue=1
hive.server2.thrift.exponential.backoff.slot.length=100ms
hive.server2.thrift.http.cookie.auth.enabled=true
hive.server2.thrift.http.cookie.is.httponly=true
hive.server2.thrift.http.cookie.is.secure=true
hive.server2.thrift.http.cookie.max.age=86400s
hive.server2.thrift.http.max.idle.time=1800s
hive.server2.thrift.http.path=cliservice
hive.server2.thrift.http.port=10001
hive.server2.thrift.http.request.header.size=6144
hive.server2.thrift.http.response.header.size=6144
hive.server2.thrift.http.worker.keepalive.time=60s
hive.server2.thrift.login.timeout=20s
hive.server2.thrift.max.message.size=104857600
hive.server2.thrift.max.worker.threads=500
hive.server2.thrift.min.worker.threads=5
hive.server2.thrift.port=10000
hive.server2.thrift.sasl.qop=auth
hive.server2.thrift.worker.keepalive.time=60s
hive.server2.transport.mode=http
hive.server2.use.SSL=true
hive.server2.xsrf.filter.enabled=false
hive.server2.zookeeper.namespace=hiveserver2
hive.server2.zookeeper.publish.configs=true
hive.service.metrics.class=org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
hive.service.metrics.file.frequency=5s
hive.service.metrics.file.location=/tmp/report.json
hive.service.metrics.hadoop2.component=hive
hive.service.metrics.hadoop2.frequency=30s
hive.service.metrics.reporter=JSON_FILE, JMX
hive.session.history.enabled=false
hive.session.id=53b42494-f97a-4cb2-bd57-d0dd37e36ea6
hive.session.silent=false
hive.skewjoin.key=100000
hive.skewjoin.mapjoin.map.tasks=10000
hive.skewjoin.mapjoin.min.split=33554432
hive.smbjoin.cache.rows=10000
hive.spark.client.connect.timeout=1000ms
hive.spark.client.future.timeout=60s
hive.spark.client.rpc.max.size=52428800
hive.spark.client.rpc.sasl.mechanisms=DIGEST-MD5
hive.spark.client.rpc.threads=8
hive.spark.client.secret.bits=256
hive.spark.client.server.connect.timeout=90000ms
hive.spark.exec.inplace.progress=true
hive.spark.job.monitor.timeout=60s
hive.ssl.protocol.blacklist=SSLv2,SSLv3
hive.stageid.rearrange=none
hive.start.cleanup.scratchdir=false
hive.stats.atomic=false
hive.stats.autogather=true
hive.stats.collect.rawdatasize=true
hive.stats.collect.scancols=false
hive.stats.collect.tablekeys=false
hive.stats.dbclass=fs
hive.stats.dbconnectionstring=jdbc:derby:;databaseName=TempStatsStore;create=true
hive.stats.deserialization.factor=1.0
hive.stats.fetch.column.stats=true
hive.stats.fetch.partition.stats=true
hive.stats.filter.in.factor=1.0
hive.stats.gather.num.threads=10
hive.stats.jdbc.timeout=30s
hive.stats.jdbcdriver=org.apache.derby.jdbc.EmbeddedDriver
hive.stats.join.factor=1.1
hive.stats.key.prefix.max.length=150
hive.stats.key.prefix.reserve.length=24
hive.stats.list.num.entries=10
hive.stats.map.num.entries=10
hive.stats.max.variable.length=100
hive.stats.ndv.error=20.0
hive.stats.reliable=false
hive.stats.retries.max=0
hive.stats.retries.wait=3000ms
hive.support.concurrency=true
hive.support.quoted.identifiers=column
hive.support.sql11.reserved.keywords=true
hive.test.authz.sstd.hs2.mode=false
hive.test.fail.compaction=false
hive.test.fail.heartbeater=false
hive.test.mode=false
hive.test.mode.prefix=test_
hive.test.mode.samplefreq=32
hive.test.rollbacktxn=false
hive.tez.auto.reducer.parallelism=true
hive.tez.container.max.java.heap.fraction=0.8
hive.tez.container.size=250
hive.tez.cpu.vcores=-1
hive.tez.dynamic.partition.pruning=true
hive.tez.dynamic.partition.pruning.max.data.size=104857600
hive.tez.dynamic.partition.pruning.max.event.size=1048576
hive.tez.enable.memory.manager=true
hive.tez.exec.inplace.progress=true
hive.tez.exec.print.summary=false
hive.tez.hs2.user.access=true
hive.tez.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat
hive.tez.java.opts=-server -Xmx200m -Djava.net.preferIPv4Stack=true
hive.tez.log.level=INFO
hive.tez.max.partition.factor=2.0
hive.tez.min.partition.factor=0.25
hive.tez.smb.number.waves=0.5
hive.tez.task.scale.memory.reserve-fraction.min=0.3
hive.tez.task.scale.memory.reserve.fraction=-1.0
hive.tez.task.scale.memory.reserve.fraction.max=0.5
hive.timedout.txn.reaper.interval=180s
hive.timedout.txn.reaper.start=100s
hive.transactional.table.scan=false
hive.transform.escape.input=false
hive.txn.heartbeat.threadpool.size=5
hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager
hive.txn.manager.dump.lock.state.on.acquire.timeout=false
hive.txn.max.open.batch=1000
hive.txn.strict.locking.mode=true
hive.txn.timeout=300
hive.typecheck.on.insert=true
hive.udtf.auto.progress=false
hive.unlock.numretries=10
hive.user.install.directory=/user/
hive.users.in.admin.role=hue,hive
hive.variable.substitute=true
hive.variable.substitute.depth=40
hive.vectorized.adaptor.usage.mode=all
hive.vectorized.execution.enabled=true
hive.vectorized.execution.mapjoin.minmax.enabled=false
hive.vectorized.execution.mapjoin.native.enabled=true
hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled=false
hive.vectorized.execution.mapjoin.native.multikey.only.enabled=false
hive.vectorized.execution.mapjoin.overflow.repeated.threshold=-1
hive.vectorized.execution.reduce.enabled=false
hive.vectorized.execution.reduce.groupby.enabled=true
hive.vectorized.groupby.checkinterval=4096
hive.vectorized.groupby.flush.percent=0.1
hive.vectorized.groupby.maxentries=100000
hive.warehouse.subdir.inherit.perms=true
hive.writeset.reaper.interval=60s
hive.zookeeper.clean.extra.nodes=false
hive.zookeeper.client.port=2181
hive.zookeeper.connection.basesleeptime=1000ms
hive.zookeeper.connection.max.retries=3
hive.zookeeper.namespace=hive_zookeeper_namespace
hive.zookeeper.quorum=sandbox.hortonworks.com:2181
hive.zookeeper.session.timeout=1200000ms
hive_metastore_user_passwd=hive
io.compression.codec.bzip2.library=system-native
io.compression.codecs=org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec
io.file.buffer.size=131072
io.map.index.interval=128
io.map.index.skip=0
io.mapfile.bloom.error.rate=0.005
io.mapfile.bloom.size=1048576
io.native.lib.available=true
io.seqfile.compress.blocksize=1000000
io.seqfile.lazydecompress=true
io.seqfile.local.dir=${hadoop.tmp.dir}/io/local
io.seqfile.sorter.recordlimit=1000000
io.serializations=org.apache.hadoop.io.serializer.WritableSerialization
io.skip.checksum.errors=false
ipc.client.connect.max.retries=50
ipc.client.connect.max.retries.on.timeouts=45
ipc.client.connect.retry.interval=1000
ipc.client.connect.timeout=20000
ipc.client.connection.maxidletime=30000
ipc.client.fallback-to-simple-auth-allowed=false
ipc.client.idlethreshold=8000
ipc.client.kill.max=10
ipc.client.ping=true
ipc.client.rpc-timeout.ms=0
ipc.maximum.data.length=67108864
ipc.ping.interval=60000
ipc.server.listen.queue.size=128
ipc.server.log.slow.rpc=false
ipc.server.max.connections=0
ipc.server.tcpnodelay=true
javax.jdo.PersistenceManagerFactoryClass=org.datanucleus.api.jdo.JDOPersistenceManagerFactory
javax.jdo.option.ConnectionDriverName=com.mysql.jdbc.Driver
javax.jdo.option.ConnectionURL=jdbc:mysql://sandbox.hortonworks.com/hive?createDatabaseIfNotExist=true
javax.jdo.option.ConnectionUserName=root
javax.jdo.option.DetachAllOnCommit=true
javax.jdo.option.Multithreaded=true
javax.jdo.option.NonTransactionalRead=true
map.sort.class=org.apache.hadoop.util.QuickSort
mapred.child.java.opts=-Xmx200m
mapreduce.admin.map.child.java.opts=-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
mapreduce.admin.reduce.child.java.opts=-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
mapreduce.admin.user.env=LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
mapreduce.am.max-attempts=2
mapreduce.app-submission.cross-platform=false
mapreduce.application.classpath=$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*:/usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/secure
mapreduce.application.framework.path=/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework
mapreduce.client.completion.pollinterval=5000
mapreduce.client.output.filter=FAILED
mapreduce.client.progressmonitor.pollinterval=1000
mapreduce.client.submit.file.replication=10
mapreduce.cluster.acls.enabled=false
mapreduce.cluster.administrators= hadoop
mapreduce.cluster.local.dir=${hadoop.tmp.dir}/mapred/local
mapreduce.cluster.temp.dir=${hadoop.tmp.dir}/mapred/temp
mapreduce.fileoutputcommitter.algorithm.version=1
mapreduce.framework.name=yarn
mapreduce.ifile.readahead=true
mapreduce.ifile.readahead.bytes=4194304
mapreduce.input.fileinputformat.input.dir.recursive=false
mapreduce.input.fileinputformat.list-status.num-threads=1
mapreduce.input.fileinputformat.split.maxsize=256000000
mapreduce.input.fileinputformat.split.minsize=1
mapreduce.input.fileinputformat.split.minsize.per.node=1
mapreduce.input.fileinputformat.split.minsize.per.rack=1
mapreduce.input.lineinputformat.linespermap=1
mapreduce.job.acl-modify-job= 
mapreduce.job.acl-view-job= 
mapreduce.job.classloader=false
mapreduce.job.committer.setup.cleanup.needed=false
mapreduce.job.committer.task.cleanup.needed=false
mapreduce.job.complete.cancel.delegation.tokens=true
mapreduce.job.counters.max=130
mapreduce.job.emit-timeline-data=false
mapreduce.job.end-notification.max.attempts=5
mapreduce.job.end-notification.max.retry.interval=5000
mapreduce.job.end-notification.retry.attempts=0
mapreduce.job.end-notification.retry.interval=1000
mapreduce.job.hdfs-servers=${fs.defaultFS}
mapreduce.job.jvm.numtasks=1
mapreduce.job.map.output.collector.class=org.apache.hadoop.mapred.MapTask$MapOutputBuffer
mapreduce.job.maps=2
mapreduce.job.max.split.locations=10
mapreduce.job.maxtaskfailures.per.tracker=3
mapreduce.job.queuename=default
mapreduce.job.reduce.shuffle.consumer.plugin.class=org.apache.hadoop.mapreduce.task.reduce.Shuffle
mapreduce.job.reduce.slowstart.completedmaps=0.05
mapreduce.job.reducer.preempt.delay.sec=0
mapreduce.job.reducer.unconditional-preempt.delay.sec=300
mapreduce.job.reduces=-1
mapreduce.job.running.map.limit=0
mapreduce.job.running.reduce.limit=0
mapreduce.job.speculative.minimum-allowed-tasks=10
mapreduce.job.speculative.retry-after-no-speculate=1000
mapreduce.job.speculative.retry-after-speculate=15000
mapreduce.job.speculative.slowtaskthreshold=1.0
mapreduce.job.speculative.speculative-cap-running-tasks=0.1
mapreduce.job.speculative.speculative-cap-total-tasks=0.01
mapreduce.job.split.metainfo.maxsize=10000000
mapreduce.job.token.tracking.ids.enabled=false
mapreduce.job.ubertask.enable=false
mapreduce.job.ubertask.maxmaps=9
mapreduce.job.ubertask.maxreduces=1
mapreduce.job.userlog.retain.hours=24
mapreduce.jobhistory.address=sandbox.hortonworks.com:10020
mapreduce.jobhistory.admin.acl=*
mapreduce.jobhistory.admin.address=0.0.0.0:10033
mapreduce.jobhistory.bind-host=0.0.0.0
mapreduce.jobhistory.cleaner.enable=true
mapreduce.jobhistory.cleaner.interval-ms=86400000
mapreduce.jobhistory.client.thread-count=10
mapreduce.jobhistory.datestring.cache.size=200000
mapreduce.jobhistory.done-dir=/mr-history/done
mapreduce.jobhistory.http.policy=HTTP_ONLY
mapreduce.jobhistory.intermediate-done-dir=/mr-history/tmp
mapreduce.jobhistory.joblist.cache.size=20000
mapreduce.jobhistory.jobname.limit=50
mapreduce.jobhistory.keytab=/etc/security/keytabs/jhs.service.keytab
mapreduce.jobhistory.loadedjobs.cache.size=5
mapreduce.jobhistory.max-age-ms=604800000
mapreduce.jobhistory.minicluster.fixed.ports=false
mapreduce.jobhistory.move.interval-ms=180000
mapreduce.jobhistory.move.thread-count=3
mapreduce.jobhistory.principal=jhs/_HOST@HDP.LOCALDOMAIN
mapreduce.jobhistory.recovery.enable=true
mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService
mapreduce.jobhistory.recovery.store.fs.uri=${hadoop.tmp.dir}/mapred/history/recoverystore
mapreduce.jobhistory.recovery.store.leveldb.path=/hadoop/mapreduce/jhs
mapreduce.jobhistory.webapp.address=sandbox.hortonworks.com:19888
mapreduce.jobhistory.webapp.https.address=0.0.0.0:19888
mapreduce.jobhistory.webapp.rest-csrf.custom-header=X-XSRF-Header
mapreduce.jobhistory.webapp.rest-csrf.enabled=false
mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore=GET,OPTIONS,HEAD
mapreduce.jobhistory.webapp.spnego-keytab-file=/etc/security/keytabs/spnego.service.keytab
mapreduce.jobhistory.webapp.spnego-principal=HTTP/_HOST@HDP.LOCALDOMAIN
mapreduce.jobhistory.webapp.xfs-filter.xframe-options=SAMEORIGIN
mapreduce.jobtracker.address=local
mapreduce.jobtracker.expire.trackers.interval=600000
mapreduce.jobtracker.handler.count=10
mapreduce.jobtracker.heartbeats.in.second=100
mapreduce.jobtracker.http.address=0.0.0.0:50030
mapreduce.jobtracker.instrumentation=org.apache.hadoop.mapred.JobTrackerMetricsInst
mapreduce.jobtracker.jobhistory.block.size=3145728
mapreduce.jobtracker.jobhistory.lru.cache.size=5
mapreduce.jobtracker.jobhistory.task.numberprogresssplits=12
mapreduce.jobtracker.maxtasks.perjob=-1
mapreduce.jobtracker.persist.jobstatus.active=true
mapreduce.jobtracker.persist.jobstatus.dir=/jobtracker/jobsInfo
mapreduce.jobtracker.persist.jobstatus.hours=1
mapreduce.jobtracker.restart.recover=false
mapreduce.jobtracker.retiredjobs.cache.size=1000
mapreduce.jobtracker.staging.root.dir=${hadoop.tmp.dir}/mapred/staging
mapreduce.jobtracker.system.dir=${hadoop.tmp.dir}/mapred/system
mapreduce.jobtracker.taskcache.levels=2
mapreduce.jobtracker.taskscheduler=org.apache.hadoop.mapred.JobQueueTaskScheduler
mapreduce.jobtracker.tasktracker.maxblacklists=4
mapreduce.jobtracker.webinterface.trusted=false
mapreduce.local.clientfactory.class.name=org.apache.hadoop.mapred.LocalClientFactory
mapreduce.map.cpu.vcores=1
mapreduce.map.java.opts=-Xmx200m
mapreduce.map.log.level=INFO
mapreduce.map.maxattempts=4
mapreduce.map.memory.mb=250
mapreduce.map.output.compress=false
mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
mapreduce.map.skip.maxrecords=0
mapreduce.map.skip.proc.count.autoincr=true
mapreduce.map.sort.spill.percent=0.7
mapreduce.map.speculative=false
mapreduce.output.fileoutputformat.compress=false
mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
mapreduce.output.fileoutputformat.compress.type=BLOCK
mapreduce.reduce.cpu.vcores=1
mapreduce.reduce.input.buffer.percent=0.0
mapreduce.reduce.java.opts=-Xmx200m
mapreduce.reduce.log.level=INFO
mapreduce.reduce.markreset.buffer.percent=0.0
mapreduce.reduce.maxattempts=4
mapreduce.reduce.memory.mb=250
mapreduce.reduce.merge.inmem.threshold=1000
mapreduce.reduce.shuffle.connect.timeout=180000
mapreduce.reduce.shuffle.fetch.retry.enabled=1
mapreduce.reduce.shuffle.fetch.retry.interval-ms=1000
mapreduce.reduce.shuffle.fetch.retry.timeout-ms=30000
mapreduce.reduce.shuffle.input.buffer.percent=0.7
mapreduce.reduce.shuffle.memory.limit.percent=0.25
mapreduce.reduce.shuffle.merge.percent=0.66
mapreduce.reduce.shuffle.parallelcopies=30
mapreduce.reduce.shuffle.read.timeout=180000
mapreduce.reduce.shuffle.retry-delay.max.ms=60000
mapreduce.reduce.skip.maxgroups=0
mapreduce.reduce.skip.proc.count.autoincr=true
mapreduce.reduce.speculative=true
mapreduce.shuffle.connection-keep-alive.enable=false
mapreduce.shuffle.connection-keep-alive.timeout=5
mapreduce.shuffle.max.connections=0
mapreduce.shuffle.max.threads=0
mapreduce.shuffle.port=13562
mapreduce.shuffle.ssl.enabled=false
mapreduce.shuffle.ssl.file.buffer.size=65536
mapreduce.shuffle.transfer.buffer.size=131072
mapreduce.task.combine.progress.records=10000
mapreduce.task.files.preserve.failedtasks=false
mapreduce.task.io.sort.factor=100
mapreduce.task.io.sort.mb=64
mapreduce.task.merge.progress.records=10000
mapreduce.task.profile=false
mapreduce.task.profile.map.params=${mapreduce.task.profile.params}
mapreduce.task.profile.maps=0-2
mapreduce.task.profile.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
mapreduce.task.profile.reduce.params=${mapreduce.task.profile.params}
mapreduce.task.profile.reduces=0-2
mapreduce.task.skip.start.attempts=2
mapreduce.task.timeout=300000
mapreduce.task.userlog.limit.kb=0
mapreduce.tasktracker.dns.interface=default
mapreduce.tasktracker.dns.nameserver=default
mapreduce.tasktracker.healthchecker.interval=60000
mapreduce.tasktracker.healthchecker.script.timeout=600000
mapreduce.tasktracker.http.address=0.0.0.0:50060
mapreduce.tasktracker.http.threads=40
mapreduce.tasktracker.indexcache.mb=10
mapreduce.tasktracker.instrumentation=org.apache.hadoop.mapred.TaskTrackerMetricsInst
mapreduce.tasktracker.local.dir.minspacekill=0
mapreduce.tasktracker.local.dir.minspacestart=0
mapreduce.tasktracker.map.tasks.maximum=2
mapreduce.tasktracker.outofband.heartbeat=false
mapreduce.tasktracker.reduce.tasks.maximum=2
mapreduce.tasktracker.report.address=127.0.0.1:0
mapreduce.tasktracker.taskcontroller=org.apache.hadoop.mapred.DefaultTaskController
mapreduce.tasktracker.taskmemorymanager.monitoringinterval=5000
mapreduce.tasktracker.tasks.sleeptimebeforesigkill=5000
net.topology.impl=org.apache.hadoop.net.NetworkTopology
net.topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping
net.topology.script.file.name=/etc/hadoop/conf/topology_script.py
net.topology.script.number.args=100
nfs.allow.insecure.ports=true
nfs.dump.dir=/tmp/.hdfs-nfs
nfs.exports.allowed.hosts=* rw
nfs.file.dump.dir=/tmp/.hdfs-nfs
nfs.kerberos.principal=nfs/_HOST@HDP.LOCALDOMAIN
nfs.keytab.file=/etc/security/keytabs/nfs.service.keytab
nfs.mountd.port=4242
nfs.rtmax=1048576
nfs.server.port=2049
nfs.wtmax=1048576
parquet.memory.pool.ratio=0.5
rpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB=org.apache.hadoop.ipc.ProtobufRpcEngine
rpc.metrics.quantile.enable=false
s3.blocksize=67108864
s3.bytes-per-checksum=512
s3.client-write-packet-size=65536
s3.replication=3
s3.stream-buffer-size=4096
s3native.blocksize=67108864
s3native.bytes-per-checksum=512
s3native.client-write-packet-size=65536
s3native.replication=3
s3native.stream-buffer-size=4096
silent=off
stream.stderr.reporter.enabled=true
stream.stderr.reporter.prefix=reporter:
tez.am.am-rm.heartbeat.interval-ms.max=250
tez.am.container.idle.release-timeout-max.millis=20000
tez.am.container.idle.release-timeout-min.millis=10000
tez.am.container.reuse.enabled=true
tez.am.container.reuse.locality.delay-allocation-millis=250
tez.am.container.reuse.non-local-fallback.enabled=false
tez.am.container.reuse.rack-fallback.enabled=true
tez.am.java.opts=-server -Xmx200m -Djava.net.preferIPv4Stack=true -XX:+UseNUMA -XX:+UseParallelGC
tez.am.launch.cluster-default.cmd-opts=-server -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
tez.am.launch.cmd-opts=-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseParallelGC
tez.am.launch.env=LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
tez.am.log.level=INFO
tez.am.max.app.attempts=2
tez.am.maxtaskfailures.per.node=10
tez.am.resource.memory.mb=256
tez.am.tez-ui.history-url.template=__HISTORY_URL_BASE__?viewPath=%2F%23%2Ftez-app%2F__APPLICATION_ID__
tez.cluster.additional.classpath.prefix=/usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/secure
tez.counters.max=10000
tez.counters.max.groups=3000
tez.dag.am.resource.memory.mb=250
tez.generate.debug.artifacts=false
tez.grouping.max-size=1073741824
tez.grouping.min-size=16777216
tez.grouping.split-waves=1.7
tez.history.logging.service.class=org.apache.tez.dag.history.logging.ats.ATSV15HistoryLoggingService
tez.history.logging.timeline-cache-plugin.old-num-dags-per-group=5
tez.lib.uris=/hdp/apps/${hdp.version}/tez/tez.tar.gz
tez.queue.name=default
tez.runtime.compress=true
tez.runtime.compress.codec=org.apache.hadoop.io.compress.SnappyCodec
tez.runtime.convert.user-payload.to.history-text=false
tez.runtime.io.sort.mb=150
tez.runtime.optimize.local.fetch=true
tez.runtime.pipelined.sorter.sort.threads=2
tez.runtime.shuffle.fetch.buffer.percent=0.6
tez.runtime.shuffle.keep-alive.enabled=true
tez.runtime.shuffle.memory.limit.percent=0.25
tez.runtime.sorter.class=PIPELINED
tez.runtime.unordered.output.buffer.size-mb=844
tez.session.am.dag.submit.timeout.secs=600
tez.session.client.timeout.secs=-1
tez.shuffle-vertex-manager.max-src-fraction=0.4
tez.shuffle-vertex-manager.min-src-fraction=0.2
tez.staging-dir=/tmp/${user.name}/staging
tez.task.am.heartbeat.counter.interval-ms.max=4000
tez.task.generate.counters.per.io=true
tez.task.get-task.sleep.interval-ms.max=200
tez.task.launch.cluster-default.cmd-opts=-server -Djava.net.preferIPv4Stack=true -Dhdp.version=${hdp.version}
tez.task.launch.cmd-opts=-Xmx256m
tez.task.launch.env=LD_LIBRARY_PATH=/usr/hdp/${hdp.version}/hadoop/lib/native:/usr/hdp/${hdp.version}/hadoop/lib/native/Linux-amd64-64
tez.task.max-events-per-heartbeat=500
tez.task.resource.memory.mb=256
tez.tez-ui.history-url.base=http://sandbox.hortonworks.com:8080/#/main/view/TEZ/tez_cluster_instance
tez.use.cluster.hadoop-libs=false
tfile.fs.input.buffer.size=262144
tfile.fs.output.buffer.size=262144
tfile.io.chunk.size=1048576
yarn.acl.enable=true
yarn.admin.acl=yarn,dr.who
yarn.am.liveness-monitor.expiry-interval-ms=600000
yarn.app.mapreduce.am.admin-command-opts=-Dhdp.version=${hdp.version}
yarn.app.mapreduce.am.command-opts=-Xmx200m
yarn.app.mapreduce.am.container.log.backups=0
yarn.app.mapreduce.am.container.log.limit.kb=0
yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size=10
yarn.app.mapreduce.am.hard-kill-timeout-ms=10000
yarn.app.mapreduce.am.job.committer.cancel-timeout=60000
yarn.app.mapreduce.am.job.committer.commit-window=10000
yarn.app.mapreduce.am.job.task.listener.thread-count=30
yarn.app.mapreduce.am.log.level=INFO
yarn.app.mapreduce.am.resource.cpu-vcores=1
yarn.app.mapreduce.am.resource.mb=250
yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms=1000
yarn.app.mapreduce.am.staging-dir=/user
yarn.app.mapreduce.client-am.ipc.max-retries=3
yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts=3
yarn.app.mapreduce.client.job.max-retries=30
yarn.app.mapreduce.client.job.retry-interval=2000
yarn.app.mapreduce.client.max-retries=3
yarn.app.mapreduce.shuffle.log.backups=0
yarn.app.mapreduce.shuffle.log.limit.kb=0
yarn.app.mapreduce.shuffle.log.separate=true
yarn.app.mapreduce.task.container.log.backups=0
yarn.application.classpath=$HADOOP_CONF_DIR,/usr/hdp/current/hadoop-client/*,/usr/hdp/current/hadoop-client/lib/*,/usr/hdp/current/hadoop-hdfs-client/*,/usr/hdp/current/hadoop-hdfs-client/lib/*,/usr/hdp/current/hadoop-yarn-client/*,/usr/hdp/current/hadoop-yarn-client/lib/*
yarn.client.application-client-protocol.poll-interval-ms=200
yarn.client.failover-proxy-provider=org.apache.hadoop.yarn.client.RequestHedgingRMFailoverProxyProvider
yarn.client.failover-retries=0
yarn.client.failover-retries-on-socket-timeouts=0
yarn.client.max-cached-nodemanagers-proxies=0
yarn.client.nodemanager-client-async.thread-pool-max-size=500
yarn.client.nodemanager-connect.max-wait-ms=120000
yarn.client.nodemanager-connect.retry-interval-ms=10000
yarn.dispatcher.drain-events.timeout=300000
yarn.fail-fast=false
yarn.http.policy=HTTP_ONLY
yarn.ipc.rpc.class=org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
yarn.log-aggregation-enable=true
yarn.log-aggregation.retain-check-interval-seconds=-1
yarn.log-aggregation.retain-seconds=2592000
yarn.log.server.url=http://sandbox.hortonworks.com:19888/jobhistory/logs
yarn.log.server.web-service.url=http://sandbox.hortonworks.com:8188/ws/v1/applicationhistory
yarn.nm.liveness-monitor.expiry-interval-ms=600000
yarn.node-labels.enabled=false
yarn.node-labels.fs-store.impl.class=org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore
yarn.node-labels.fs-store.retry-policy-spec=2000, 500
yarn.node-labels.fs-store.root-dir=/system/yarn/node-labels
yarn.nodemanager.address=0.0.0.0:45454
yarn.nodemanager.admin-env=MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX
yarn.nodemanager.aux-services=mapreduce_shuffle,spark_shuffle,spark2_shuffle
yarn.nodemanager.aux-services.mapreduce_shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
yarn.nodemanager.aux-services.spark2_shuffle.class=org.apache.spark.network.yarn.YarnShuffleService
yarn.nodemanager.aux-services.spark2_shuffle.classpath=/usr/hdp/${hdp.version}/spark2/aux/*
yarn.nodemanager.aux-services.spark_shuffle.class=org.apache.spark.network.yarn.YarnShuffleService
yarn.nodemanager.aux-services.spark_shuffle.classpath=/usr/hdp/${hdp.version}/spark/aux/*
yarn.nodemanager.bind-host=0.0.0.0
yarn.nodemanager.container-executor.class=org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor
yarn.nodemanager.container-manager.thread-count=20
yarn.nodemanager.container-metrics.unregister-delay-ms=60000
yarn.nodemanager.container-monitor.interval-ms=3000
yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled=false
yarn.nodemanager.delete.debug-delay-sec=0
yarn.nodemanager.delete.thread-count=4
yarn.nodemanager.disk-health-checker.interval-ms=120000
yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=90
yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb=1000
yarn.nodemanager.disk-health-checker.min-healthy-disks=0.25
yarn.nodemanager.docker-container-executor.exec-name=/usr/bin/docker
yarn.nodemanager.env-whitelist=JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME
yarn.nodemanager.health-checker.interval-ms=135000
yarn.nodemanager.health-checker.script.timeout-ms=120000
yarn.nodemanager.hostname=0.0.0.0
yarn.nodemanager.keytab=/etc/security/keytabs/nm.service.keytab
yarn.nodemanager.linux-container-executor.cgroups.hierarchy=/hadoop-yarn
yarn.nodemanager.linux-container-executor.cgroups.mount=false
yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage=false
yarn.nodemanager.linux-container-executor.group=hadoop
yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users=true
yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user=nobody
yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern=^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$
yarn.nodemanager.linux-container-executor.resources-handler.class=org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
yarn.nodemanager.local-cache.max-files-per-directory=8192
yarn.nodemanager.local-dirs=/hadoop/yarn/local
yarn.nodemanager.localizer.address=${yarn.nodemanager.hostname}:8040
yarn.nodemanager.localizer.cache.cleanup.interval-ms=600000
yarn.nodemanager.localizer.cache.target-size-mb=10240
yarn.nodemanager.localizer.client.thread-count=5
yarn.nodemanager.localizer.fetch.thread-count=4
yarn.nodemanager.log-aggregation.compression-type=gz
yarn.nodemanager.log-aggregation.debug-enabled=false
yarn.nodemanager.log-aggregation.num-log-files-per-app=336
yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds=-1
yarn.nodemanager.log-container-debug-info.enabled=true
yarn.nodemanager.log-dirs=/hadoop/yarn/log
yarn.nodemanager.log.retain-second=604800
yarn.nodemanager.log.retain-seconds=604800
yarn.nodemanager.logaggregation.threadpool-size-max=100
yarn.nodemanager.pmem-check-enabled=false
yarn.nodemanager.principal=nm/_HOST@HDP.LOCALDOMAIN
yarn.nodemanager.process-kill-wait.ms=2000
yarn.nodemanager.recovery.compaction-interval-secs=3600
yarn.nodemanager.recovery.dir=/var/log/hadoop-yarn/nodemanager/recovery-state
yarn.nodemanager.recovery.enabled=true
yarn.nodemanager.remote-app-log-dir=/app-logs
yarn.nodemanager.remote-app-log-dir-suffix=logs
yarn.nodemanager.resource.cpu-vcores=8
yarn.nodemanager.resource.memory-mb=3000
yarn.nodemanager.resource.percentage-physical-cpu-limit=80
yarn.nodemanager.resourcemanager.minimum.version=NONE
yarn.nodemanager.runtime.linux.docker.allowed-container-networks=host,none,bridge
yarn.nodemanager.runtime.linux.docker.capabilities=CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE
yarn.nodemanager.runtime.linux.docker.default-container-network=host
yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed=false
yarn.nodemanager.sleep-delay-before-sigkill.ms=250
yarn.nodemanager.vmem-check-enabled=false
yarn.nodemanager.vmem-pmem-ratio=5
yarn.nodemanager.webapp.address=${yarn.nodemanager.hostname}:8042
yarn.nodemanager.webapp.cross-origin.enabled=false
yarn.nodemanager.webapp.https.address=0.0.0.0:8044
yarn.nodemanager.webapp.rest-csrf.custom-header=X-XSRF-Header
yarn.nodemanager.webapp.rest-csrf.enabled=false
yarn.nodemanager.webapp.rest-csrf.methods-to-ignore=GET,OPTIONS,HEAD
yarn.nodemanager.webapp.spnego-keytab-file=/etc/security/keytabs/spnego.service.keytab
yarn.nodemanager.webapp.spnego-principal=HTTP/_HOST@HDP.LOCALDOMAIN
yarn.nodemanager.webapp.xfs-filter.xframe-options=SAMEORIGIN
yarn.nodemanager.windows-container.cpu-limit.enabled=false
yarn.nodemanager.windows-container.memory-limit.enabled=false
yarn.resourcemanager.address=sandbox.hortonworks.com:8032
yarn.resourcemanager.admin.address=sandbox.hortonworks.com:8141
yarn.resourcemanager.admin.client.thread-count=1
yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs=86400
yarn.resourcemanager.am.max-attempts=2
yarn.resourcemanager.amlauncher.log.command=false
yarn.resourcemanager.amlauncher.thread-count=50
yarn.resourcemanager.bind-host=0.0.0.0
yarn.resourcemanager.client.thread-count=50
yarn.resourcemanager.configuration.provider-class=org.apache.hadoop.yarn.LocalConfigurationProvider
yarn.resourcemanager.connect.max-wait.ms=900000
yarn.resourcemanager.connect.retry-interval.ms=30000
yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs=86400
yarn.resourcemanager.container.liveness-monitor.interval-ms=600000
yarn.resourcemanager.delayed.delegation-token.removal-interval-ms=30000
yarn.resourcemanager.delegation-token.max-conf-size-bytes=12800
yarn.resourcemanager.fail-fast=${yarn.fail-fast}
yarn.resourcemanager.fs.state-store.num-retries=0
yarn.resourcemanager.fs.state-store.retry-interval-ms=1000
yarn.resourcemanager.fs.state-store.retry-policy-spec=2000, 500
yarn.resourcemanager.fs.state-store.uri= 
yarn.resourcemanager.ha.automatic-failover.embedded=true
yarn.resourcemanager.ha.automatic-failover.enabled=true
yarn.resourcemanager.ha.automatic-failover.zk-base-path=/yarn-leader-election
yarn.resourcemanager.ha.enabled=false
yarn.resourcemanager.hostname=sandbox.hortonworks.com
yarn.resourcemanager.keytab=/etc/security/keytabs/rm.service.keytab
yarn.resourcemanager.leveldb-state-store.compaction-interval-secs=3600
yarn.resourcemanager.leveldb-state-store.path=${hadoop.tmp.dir}/yarn/system/rmstore
yarn.resourcemanager.max-completed-applications=10000
yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory=10
yarn.resourcemanager.nodemanager-connect-retries=10
yarn.resourcemanager.nodemanager.minimum.version=NONE
yarn.resourcemanager.nodemanagers.heartbeat-interval-ms=1000
yarn.resourcemanager.nodes.exclude-path=/etc/hadoop/conf/yarn.exclude
yarn.resourcemanager.principal=rm/_HOST@HDP.LOCALDOMAIN
yarn.resourcemanager.proxy-user-privileges.enabled=true
yarn.resourcemanager.recovery.enabled=false
yarn.resourcemanager.resource-tracker.address=sandbox.hortonworks.com:8025
yarn.resourcemanager.resource-tracker.client.thread-count=50
yarn.resourcemanager.scheduler.address=sandbox.hortonworks.com:8030
yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
yarn.resourcemanager.scheduler.client.thread-count=50
yarn.resourcemanager.scheduler.monitor.enable=false
yarn.resourcemanager.scheduler.monitor.policies=org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
yarn.resourcemanager.state-store.max-completed-applications=${yarn.resourcemanager.max-completed-applications}
yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore
yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size=10
yarn.resourcemanager.system-metrics-publisher.enabled=true
yarn.resourcemanager.webapp.address=sandbox.hortonworks.com:8088
yarn.resourcemanager.webapp.cross-origin.enabled=true
yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled=false
yarn.resourcemanager.webapp.https.address=sandbox.hortonworks.com:8090
yarn.resourcemanager.webapp.proxyuser.hcat.groups=*
yarn.resourcemanager.webapp.proxyuser.hcat.hosts=*
yarn.resourcemanager.webapp.proxyuser.oozie.groups=*
yarn.resourcemanager.webapp.proxyuser.oozie.hosts=*
yarn.resourcemanager.webapp.rest-csrf.custom-header=X-XSRF-Header
yarn.resourcemanager.webapp.rest-csrf.enabled=false
yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore=GET,OPTIONS,HEAD
yarn.resourcemanager.webapp.spnego-keytab-file=/etc/security/keytabs/spnego.service.keytab
yarn.resourcemanager.webapp.spnego-principal=HTTP/_HOST@HDP.LOCALDOMAIN
yarn.resourcemanager.webapp.xfs-filter.xframe-options=SAMEORIGIN
yarn.resourcemanager.work-preserving-recovery.enabled=true
yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms=10000
yarn.resourcemanager.zk-acl=sasl:rm:rwcda
yarn.resourcemanager.zk-address=sandbox.hortonworks.com:2181
yarn.resourcemanager.zk-num-retries=1000
yarn.resourcemanager.zk-retry-interval-ms=1000
yarn.resourcemanager.zk-state-store.parent-path=/rmstore
yarn.resourcemanager.zk-timeout-ms=10000
yarn.scheduler.capacity.ordering-policy.priority-utilization.underutilized-preemption.enabled=false
yarn.scheduler.maximum-allocation-mb=2250
yarn.scheduler.maximum-allocation-vcores=8
yarn.scheduler.minimum-allocation-mb=250
yarn.scheduler.minimum-allocation-vcores=1
yarn.sharedcache.admin.address=0.0.0.0:8047
yarn.sharedcache.admin.thread-count=1
yarn.sharedcache.app-checker.class=org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker
yarn.sharedcache.checksum.algo.impl=org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl
yarn.sharedcache.cleaner.initial-delay-mins=10
yarn.sharedcache.cleaner.period-mins=1440
yarn.sharedcache.cleaner.resource-sleep-ms=0
yarn.sharedcache.client-server.address=0.0.0.0:8045
yarn.sharedcache.client-server.thread-count=50
yarn.sharedcache.enabled=false
yarn.sharedcache.nested-level=3
yarn.sharedcache.nm.uploader.replication.factor=10
yarn.sharedcache.nm.uploader.thread-count=20
yarn.sharedcache.root-dir=/sharedcache
yarn.sharedcache.store.class=org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore
yarn.sharedcache.store.in-memory.check-period-mins=720
yarn.sharedcache.store.in-memory.initial-delay-mins=10
yarn.sharedcache.store.in-memory.staleness-period-mins=10080
yarn.sharedcache.uploader.server.address=0.0.0.0:8046
yarn.sharedcache.uploader.server.thread-count=50
yarn.sharedcache.webapp.address=0.0.0.0:8788
yarn.timeline-service.address=sandbox.hortonworks.com:10200
yarn.timeline-service.bind-host=0.0.0.0
yarn.timeline-service.client.best-effort=false
yarn.timeline-service.client.fd-clean-interval-secs=60
yarn.timeline-service.client.fd-flush-interval-secs=5
yarn.timeline-service.client.fd-retain-secs=300
yarn.timeline-service.client.internal-timers-ttl-secs=420
yarn.timeline-service.client.max-retries=30
yarn.timeline-service.client.retry-interval-ms=1000
yarn.timeline-service.enabled=true
yarn.timeline-service.entity-group-fs-store.active-dir=/ats/active/
yarn.timeline-service.entity-group-fs-store.app-cache-size=10
yarn.timeline-service.entity-group-fs-store.cache-store-class=org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore
yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds=3600
yarn.timeline-service.entity-group-fs-store.done-dir=/ats/done/
yarn.timeline-service.entity-group-fs-store.group-id-plugin-classes=org.apache.tez.dag.history.logging.ats.TimelineCachePluginImpl
yarn.timeline-service.entity-group-fs-store.group-id-plugin-classpath=/usr/hdp/${hdp.version}/spark/hdpLib/*
yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size=10485760
yarn.timeline-service.entity-group-fs-store.retain-seconds=604800
yarn.timeline-service.entity-group-fs-store.scan-interval-seconds=60
yarn.timeline-service.entity-group-fs-store.summary-store=org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore
yarn.timeline-service.generic-application-history.max-applications=10000
yarn.timeline-service.generic-application-history.save-non-am-container-meta-info=false
yarn.timeline-service.generic-application-history.store-class=org.apache.hadoop.yarn.server.applicationhistoryservice.NullApplicationHistoryStore
yarn.timeline-service.handler-thread-count=10
yarn.timeline-service.hostname=0.0.0.0
yarn.timeline-service.http-authentication.kerberos.keytab=/etc/security/keytabs/spnego.service.keytab
yarn.timeline-service.http-authentication.kerberos.principal=HTTP/_HOST@HDP.LOCALDOMAIN
yarn.timeline-service.http-authentication.proxyuser.ambari-server-sandbox.groups=*
yarn.timeline-service.http-authentication.proxyuser.ambari-server-sandbox.hosts=sandbox.hortonworks.com
yarn.timeline-service.http-authentication.proxyuser.root.users=*
yarn.timeline-service.http-authentication.simple.anonymous.allowed=true
yarn.timeline-service.http-authentication.type=kerberos
yarn.timeline-service.keytab=/etc/security/keytabs/yarn.service.keytab
yarn.timeline-service.leveldb-state-store.path=/hadoop/yarn/timeline
yarn.timeline-service.leveldb-timeline-store.path=/hadoop/yarn/timeline
yarn.timeline-service.leveldb-timeline-store.read-cache-size=104857600
yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size=10000
yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size=10000
yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms=300000
yarn.timeline-service.plugin.enabled=true
yarn.timeline-service.principal=yarn/_HOST@HDP.LOCALDOMAIN
yarn.timeline-service.recovery.enabled=true
yarn.timeline-service.state-store-class=org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore
yarn.timeline-service.store-class=org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore
yarn.timeline-service.ttl-enable=true
yarn.timeline-service.ttl-ms=2678400000
yarn.timeline-service.version=1.5
yarn.timeline-service.webapp.address=sandbox.hortonworks.com:8188
yarn.timeline-service.webapp.https.address=sandbox.hortonworks.com:8190
yarn.timeline-service.webapp.rest-csrf.custom-header=X-XSRF-Header
yarn.timeline-service.webapp.rest-csrf.enabled=true
yarn.timeline-service.webapp.rest-csrf.methods-to-ignore=GET,OPTIONS,HEAD
yarn.timeline-service.webapp.xfs-filter.xframe-options=SAMEORIGIN
yarn.webapp.xfs-filter.enabled=true
env:ATLAS_HOME=/usr/hdp/2.6.0.3-8/atlas
env:CLASSPATH=:/hook/hive:/usr/hdp/2.6.0.3-8/atlas/hook/hive/*:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/hcatalog/hive-hcatalog-core-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/hcatalog/hive-hcatalog-server-extensions-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/webhcat/java-client/hive-webhcat-java-client-1.2.1000.2.6.0.3-8.jar:/usr/hdp/current/hive-client/conf:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-core-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-fate-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-start-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-trace-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/activation-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/ant-1.9.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/ant-launcher-1.9.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/antlr-2.7.7.jar:/usr/hdp/2.6.0.3-8/hive/lib/antlr-runtime-3.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/apache-log4j-extras-1.2.17.jar:/usr/hdp/2.6.0.3-8/hive/lib/asm-commons-3.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/asm-tree-3.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/avatica-1.8.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/avatica-metrics-1.8.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/avro-1.7.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/bonecp-0.8.0.RELEASE.jar:/usr/hdp/2.6.0.3-8/hive/lib/calcite-core-1.2.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/calcite-linq4j-1.2.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-cli-1.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-codec-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-collections-3.2.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-compiler-2.7.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-compress-1.4.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-dbcp-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-httpclient-3.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-lang-2.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-logging-1.1.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-math-2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-pool-1.5.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-vfs2-2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-client-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-framework-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-api-jdo-4.2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-core-4.1.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-rdbms-4.1.7.jar:/usr/hdp/2.6.0.3-8/hive/lib/derby-10.10.2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/eigenbase-properties-1.1.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-annotation_1.0_spec-1.1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-jaspic_1.0_spec-1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-jta_1.1_spec-1.1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/groovy-all-2.4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/guava-14.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/HikariCP-2.5.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-accumulo-handler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-accumulo-handler.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-ant-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-ant.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-beeline-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-beeline.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-cli-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-cli.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-common-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-common.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-contrib-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-contrib.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-exec-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-exec.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hbase-handler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hbase-handler.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hwi-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hwi.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-jdbc-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-jdbc.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-metastore-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-metastore.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-serde-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-serde.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-service-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-service.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-0.20S-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-0.23-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-common-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-common.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-scheduler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-scheduler.jar:/usr/hdp/2.6.0.3-8/hive/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hive/lib/httpclient-4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/httpcore-4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/ivy-2.4.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-annotations-2.4.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-core-2.4.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-databind-2.4.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/janino-2.7.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/javax.jdo-3.2.0-m3.jar:/usr/hdp/2.6.0.3-8/hive/lib/jcommander-1.32.jar:/usr/hdp/2.6.0.3-8/hive/lib/jdo-api-3.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/jetty-all-7.6.0.v20120127.jar:/usr/hdp/2.6.0.3-8/hive/lib/jetty-all-server-7.6.0.v20120127.jar:/usr/hdp/2.6.0.3-8/hive/lib/jline-2.12.jar:/usr/hdp/2.6.0.3-8/hive/lib/joda-time-2.8.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/jpam-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/json-20090211.jar:/usr/hdp/2.6.0.3-8/hive/lib/jsr305-3.0.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jta-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/libfb303-0.9.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/libthrift-0.9.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/log4j-1.2.16.jar:/usr/hdp/2.6.0.3-8/hive/lib/mail-1.4.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-api-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-provider-svn-commons-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-provider-svnexe-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-core-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-json-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-jvm-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/mysql-connector-java.jar:/usr/hdp/2.6.0.3-8/hive/lib/netty-3.7.0.Final.jar:/usr/hdp/2.6.0.3-8/hive/lib/ojdbc6.jar:/usr/hdp/2.6.0.3-8/hive/lib/opencsv-2.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/oro-2.0.8.jar:/usr/hdp/2.6.0.3-8/hive/lib/paranamer-2.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/parquet-hadoop-bundle-1.8.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/usr/hdp/2.6.0.3-8/hive/lib/plexus-utils-1.5.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/ranger-hive-plugin-shim-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/ranger-plugin-classloader-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/regexp-1.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/servlet-api-2.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/snappy-java-1.0.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/ST4-4.0.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/stax-api-1.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/stringtemplate-3.2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/super-csv-2.2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/transaction-api-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/velocity-1.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/xz-1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/zookeeper-3.4.6.2.6.0.3-8.jar::/usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar:/etc/hbase/conf:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-common-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-client-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-hadoop-compat-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-server-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-protocol-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.6.0.3-8/hbase/lib/metrics-core-2.2.0.jar:jdbc-mysql.jar:mysql-connector-java-5.1.17.jar:mysql-connector-java-5.1.37.jar:mysql-connector-java.jar:/usr/hdp/2.6.0.3-8/hadoop/conf:/usr/hdp/2.6.0.3-8/hadoop/lib/*:/usr/hdp/2.6.0.3-8/hadoop/.//*:/usr/hdp/2.6.0.3-8/hadoop-hdfs/./:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/*:/usr/hdp/2.6.0.3-8/hadoop-hdfs/.//*:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/*:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//*:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/*:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//*:/usr/hdp/2.6.0.3-8/tez/*:/usr/hdp/2.6.0.3-8/tez/lib/*:/usr/hdp/2.6.0.3-8/tez/conf
env:CVS_RSH=ssh
env:G_BROKEN_FILENAMES=1
env:HADOOP_CLASSPATH=:/hook/hive:/usr/hdp/2.6.0.3-8/atlas/hook/hive/*:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/hcatalog/hive-hcatalog-core-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/hcatalog/hive-hcatalog-server-extensions-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/webhcat/java-client/hive-webhcat-java-client-1.2.1000.2.6.0.3-8.jar:/usr/hdp/current/hive-client/conf:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-core-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-fate-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-start-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-trace-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/activation-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/ant-1.9.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/ant-launcher-1.9.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/antlr-2.7.7.jar:/usr/hdp/2.6.0.3-8/hive/lib/antlr-runtime-3.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/apache-log4j-extras-1.2.17.jar:/usr/hdp/2.6.0.3-8/hive/lib/asm-commons-3.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/asm-tree-3.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/avatica-1.8.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/avatica-metrics-1.8.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/avro-1.7.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/bonecp-0.8.0.RELEASE.jar:/usr/hdp/2.6.0.3-8/hive/lib/calcite-core-1.2.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/calcite-linq4j-1.2.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-cli-1.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-codec-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-collections-3.2.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-compiler-2.7.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-compress-1.4.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-dbcp-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-httpclient-3.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-lang-2.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-logging-1.1.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-math-2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-pool-1.5.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-vfs2-2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-client-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-framework-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-api-jdo-4.2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-core-4.1.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-rdbms-4.1.7.jar:/usr/hdp/2.6.0.3-8/hive/lib/derby-10.10.2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/eigenbase-properties-1.1.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-annotation_1.0_spec-1.1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-jaspic_1.0_spec-1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-jta_1.1_spec-1.1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/groovy-all-2.4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/guava-14.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/HikariCP-2.5.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-accumulo-handler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-accumulo-handler.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-ant-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-ant.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-beeline-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-beeline.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-cli-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-cli.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-common-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-common.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-contrib-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-contrib.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-exec-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-exec.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hbase-handler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hbase-handler.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hwi-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hwi.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-jdbc-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-jdbc.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-metastore-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-metastore.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-serde-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-serde.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-service-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-service.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-0.20S-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-0.23-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-common-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-common.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-scheduler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-scheduler.jar:/usr/hdp/2.6.0.3-8/hive/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hive/lib/httpclient-4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/httpcore-4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/ivy-2.4.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-annotations-2.4.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-core-2.4.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-databind-2.4.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/janino-2.7.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/javax.jdo-3.2.0-m3.jar:/usr/hdp/2.6.0.3-8/hive/lib/jcommander-1.32.jar:/usr/hdp/2.6.0.3-8/hive/lib/jdo-api-3.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/jetty-all-7.6.0.v20120127.jar:/usr/hdp/2.6.0.3-8/hive/lib/jetty-all-server-7.6.0.v20120127.jar:/usr/hdp/2.6.0.3-8/hive/lib/jline-2.12.jar:/usr/hdp/2.6.0.3-8/hive/lib/joda-time-2.8.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/jpam-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/json-20090211.jar:/usr/hdp/2.6.0.3-8/hive/lib/jsr305-3.0.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jta-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/libfb303-0.9.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/libthrift-0.9.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/log4j-1.2.16.jar:/usr/hdp/2.6.0.3-8/hive/lib/mail-1.4.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-api-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-provider-svn-commons-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-provider-svnexe-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-core-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-json-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-jvm-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/mysql-connector-java.jar:/usr/hdp/2.6.0.3-8/hive/lib/netty-3.7.0.Final.jar:/usr/hdp/2.6.0.3-8/hive/lib/ojdbc6.jar:/usr/hdp/2.6.0.3-8/hive/lib/opencsv-2.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/oro-2.0.8.jar:/usr/hdp/2.6.0.3-8/hive/lib/paranamer-2.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/parquet-hadoop-bundle-1.8.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/usr/hdp/2.6.0.3-8/hive/lib/plexus-utils-1.5.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/ranger-hive-plugin-shim-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/ranger-plugin-classloader-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/regexp-1.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/servlet-api-2.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/snappy-java-1.0.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/ST4-4.0.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/stax-api-1.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/stringtemplate-3.2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/super-csv-2.2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/transaction-api-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/velocity-1.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/xz-1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/zookeeper-3.4.6.2.6.0.3-8.jar::/usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar:/etc/hbase/conf:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-common-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-client-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-hadoop-compat-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-server-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-protocol-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.6.0.3-8/hbase/lib/metrics-core-2.2.0.jar:jdbc-mysql.jar:mysql-connector-java-5.1.17.jar:mysql-connector-java-5.1.37.jar:mysql-connector-java.jar:/usr/hdp/2.6.0.3-8/tez/*:/usr/hdp/2.6.0.3-8/tez/lib/*:/usr/hdp/2.6.0.3-8/tez/conf
env:HADOOP_CLIENT_OPTS=-Xmx250m   -Xmx1024m -Djava.util.logging.config.file=/usr/hdp/current/hive-client/conf/parquet-logging.properties 
env:HADOOP_CONF_DIR=/usr/hdp/2.6.0.3-8/hadoop/conf
env:HADOOP_DATANODE_OPTS=-server -XX:ParallelGCThreads=4 -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hadoop/hive/hs_err_pid%p.log -XX:NewSize=200m -XX:MaxNewSize=200m -Xloggc:/var/log/hadoop/hive/gc.log-201712060031 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xms250m -Xmx250m -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT  -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly
env:HADOOP_HEAPSIZE=250
env:HADOOP_HOME=/usr/hdp/2.6.0.3-8/hadoop
env:HADOOP_HOME_WARN_SUPPRESS=1
env:HADOOP_IDENT_STRING=hive
env:HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec
env:HADOOP_LOG_DIR=/var/log/hadoop/hive
env:HADOOP_MAPRED_HOME=/usr/hdp/2.6.0.3-8/hadoop-mapreduce
env:HADOOP_MAPRED_LOG_DIR=/var/log/hadoop-mapreduce/hive
env:HADOOP_MAPRED_PID_DIR=/var/run/hadoop-mapreduce/hive
env:HADOOP_NAMENODE_INIT_HEAPSIZE=-Xms250m
env:HADOOP_NAMENODE_OPTS=-server -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hadoop/hive/hs_err_pid%p.log -XX:NewSize=50m -XX:MaxNewSize=100m -Xloggc:/var/log/hadoop/hive/gc.log-201712060031 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly -Xms250m -Xmx250m -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT -XX:OnOutOfMemoryError="/usr/hdp/current/hadoop-hdfs-namenode/bin/kill-name-node" -Dorg.mortbay.jetty.Request.maxFormContentSize=-1 
env:HADOOP_OPTS=-Dhdp.version=2.6.0.3-8 -Djava.net.preferIPv4Stack=true  -XX:NewRatio=12 -XX:MaxHeapFreeRatio=40 -XX:MinHeapFreeRatio=15 -XX:+UseNUMA -XX:+UseParallelGC -XX:-UseGCOverheadLimit -Dhdp.version=2.6.0.3-8 -Dhadoop.log.dir=/var/log/hadoop/hive -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/usr/hdp/2.6.0.3-8/hadoop -Dhadoop.id.str=hive -Dhadoop.root.logger=INFO,console -Djava.library.path=:/usr/hdp/2.6.0.3-8/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.6.0.3-8/hadoop/lib/native -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Xmx250m   -Xmx1024m -Djava.util.logging.config.file=/usr/hdp/current/hive-client/conf/parquet-logging.properties  -Dhadoop.security.logger=INFO,NullAppender
env:HADOOP_PID_DIR=/var/run/hadoop/hive
env:HADOOP_PREFIX=/usr/hdp/2.6.0.3-8/hadoop
env:HADOOP_SECONDARYNAMENODE_OPTS=-server -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hadoop/hive/hs_err_pid%p.log -XX:NewSize=50m -XX:MaxNewSize=100m -Xloggc:/var/log/hadoop/hive/gc.log-201712060031 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly -Xms250m -Xmx250m -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT -XX:OnOutOfMemoryError="/usr/hdp/current/hadoop-hdfs-secondarynamenode/bin/kill-secondary-name-node" 
env:HADOOP_SECURE_DN_LOG_DIR=/var/log/hadoop/hdfs
env:HADOOP_SECURE_DN_PID_DIR=/var/run/hadoop/hdfs
env:HADOOP_SECURE_DN_USER=hdfs
env:HADOOP_SSH_OPTS=-o ConnectTimeout=5 -o SendEnv=HADOOP_CONF_DIR
env:HADOOP_USER_CLASSPATH_FIRST=true
env:HADOOP_YARN_HOME=/usr/hdp/2.6.0.3-8/hadoop-yarn
env:HDP_VERSION=2.6.0.3-8
env:HISTCONTROL=ignoredups
env:HISTSIZE=1000
env:HIVE_AUX_JARS_PATH=/usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar
env:HIVE_CONF_DIR=/usr/hdp/current/hive-client/conf
env:HIVE_HOME=/usr/hdp/2.6.0.3-8/hive
env:HIVE_SKIP_SPARK_ASSEMBLY=true
env:HOME=/home/hive
env:HOSTNAME=sandbox.hortonworks.com
env:JAVA_HOME=/usr/lib/jvm/java
env:JAVA_LIBRARY_PATH=:/usr/hdp/2.6.0.3-8/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.6.0.3-8/hadoop/lib/native
env:JSVC_HOME=/usr/lib/bigtop-utils
env:LANG=en_US.UTF-8
env:LD_LIBRARY_PATH=::/usr/hdp/2.6.0.3-8/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.6.0.3-8/hadoop/lib/native
env:LESSOPEN=||/usr/bin/lesspipe.sh %s
env:LOGNAME=hive
env:LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.tbz=01;31:*.tbz2=01;31:*.bz=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:
env:MAIL=/var/spool/mail/hive
env:MALLOC_ARENA_MAX=4
env:METASTORE_PORT=9083
env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
env:PATH=/usr/lib64/qt-3.3/bin:/usr/lib/jvm/java/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/hdp/current/falcon-client/bin:/usr/hdp/current/hadoop-mapreduce-historyserver/bin:/usr/hdp/current/oozie-client/bin:/usr/hdp/current/falcon-server/bin:/usr/hdp/current/hadoop-yarn-client/bin:/usr/hdp/current/oozie-server/bin:/usr/hdp/current/flume-client/bin:/usr/hdp/current/hadoop-yarn-nodemanager/bin:/usr/hdp/current/pig-client/bin:/usr/hdp/current/flume-server/bin:/usr/hdp/current/hadoop-yarn-resourcemanager/bin:/usr/hdp/current/slider-client/bin:/usr/hdp/current/hadoop-client/bin:/usr/hdp/current/hadoop-yarn-timelineserver/bin:/usr/hdp/current/sqoop-client/bin:/usr/hdp/current/hadoop-hdfs-client/bin:/usr/hdp/current/hbase-client/bin:/usr/hdp/current/sqoop-server/bin:/usr/hdp/current/hadoop-hdfs-datanode/bin:/usr/hdp/current/hbase-master/bin:/usr/hdp/current/storm-client/bin:/usr/hdp/current/hadoop-hdfs-journalnode/bin:/usr/hdp/current/hbase-regionserver/bin:/usr/hdp/current/storm-nimbus/bin:/usr/hdp/current/hadoop-hdfs-namenode/bin:/usr/hdp/current/hive-client/bin:/usr/hdp/current/storm-supervisor/bin:/usr/hdp/current/hadoop-hdfs-nfs3/bin:/usr/hdp/current/hive-metastore/bin:/usr/hdp/current/zookeeper-client/bin:/usr/hdp/current/hadoop-hdfs-portmap/bin:/usr/hdp/current/hive-server2/bin:/usr/hdp/current/zookeeper-server/bin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/bin:/usr/hdp/current/hive-webhcat/bin:/usr/hdp/current/hadoop-mapreduce-client/bin:/usr/hdp/current/knox-server/bin:/usr/hdp/current/hadoop-client/sbin:/usr/hdp/current/hadoop-hdfs-nfs3/sbin:/usr/hdp/current/hadoop-yarn-client/sbin:/usr/hdp/current/hadoop-hdfs-client/sbin:/usr/hdp/current/hadoop-hdfs-portmap/sbin:/usr/hdp/current/hadoop-yarn-nodemanager/sbin:/usr/hdp/current/hadoop-hdfs-datanode/sbin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/sbin:/usr/hdp/current/hadoop-yarn-resourcemanager/sbin:/usr/hdp/current/hadoop-hdfs-journalnode/sbin:/usr/hdp/current/hadoop-mapreduce-client/sbin:/usr/hdp/current/hadoop-yarn-timelineserver/sbin:/usr/hdp/current/hadoop-hdfs-namenode/sbin:/usr/hdp/current/hadoop-mapreduce-historyserver/sbin:/usr/hdp/current/hive-webhcat/sbin:/home/hive/bin:/usr/hdp/current/falcon-client/bin:/usr/hdp/current/hadoop-mapreduce-historyserver/bin:/usr/hdp/current/oozie-client/bin:/usr/hdp/current/falcon-server/bin:/usr/hdp/current/hadoop-yarn-client/bin:/usr/hdp/current/oozie-server/bin:/usr/hdp/current/flume-client/bin:/usr/hdp/current/hadoop-yarn-nodemanager/bin:/usr/hdp/current/pig-client/bin:/usr/hdp/current/flume-server/bin:/usr/hdp/current/hadoop-yarn-resourcemanager/bin:/usr/hdp/current/slider-client/bin:/usr/hdp/current/hadoop-client/bin:/usr/hdp/current/hadoop-yarn-timelineserver/bin:/usr/hdp/current/sqoop-client/bin:/usr/hdp/current/hadoop-hdfs-client/bin:/usr/hdp/current/hbase-client/bin:/usr/hdp/current/sqoop-server/bin:/usr/hdp/current/hadoop-hdfs-datanode/bin:/usr/hdp/current/hbase-master/bin:/usr/hdp/current/storm-client/bin:/usr/hdp/current/hadoop-hdfs-journalnode/bin:/usr/hdp/current/hbase-regionserver/bin:/usr/hdp/current/storm-nimbus/bin:/usr/hdp/current/hadoop-hdfs-namenode/bin:/usr/hdp/current/hive-client/bin:/usr/hdp/current/storm-supervisor/bin:/usr/hdp/current/hadoop-hdfs-nfs3/bin:/usr/hdp/current/hive-metastore/bin:/usr/hdp/current/zookeeper-client/bin:/usr/hdp/current/hadoop-hdfs-portmap/bin:/usr/hdp/current/hive-server2/bin:/usr/hdp/current/zookeeper-server/bin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/bin:/usr/hdp/current/hive-webhcat/bin:/usr/hdp/current/hadoop-mapreduce-client/bin:/usr/hdp/current/knox-server/bin:/usr/hdp/current/hadoop-client/sbin:/usr/hdp/current/hadoop-hdfs-nfs3/sbin:/usr/hdp/current/hadoop-yarn-client/sbin:/usr/hdp/current/hadoop-hdfs-client/sbin:/usr/hdp/current/hadoop-hdfs-portmap/sbin:/usr/hdp/current/hadoop-yarn-nodemanager/sbin:/usr/hdp/current/hadoop-hdfs-datanode/sbin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/sbin:/usr/hdp/current/hadoop-yarn-resourcemanager/sbin:/usr/hdp/current/hadoop-hdfs-journalnode/sbin:/usr/hdp/current/hadoop-mapreduce-client/sbin:/usr/hdp/current/hadoop-yarn-timelineserver/sbin:/usr/hdp/current/hadoop-hdfs-namenode/sbin:/usr/hdp/current/hadoop-mapreduce-historyserver/sbin:/usr/hdp/current/hive-webhcat/sbin
env:PWD=/home/hive
env:QTDIR=/usr/lib64/qt-3.3
env:QTINC=/usr/lib64/qt-3.3/include
env:QTLIB=/usr/lib64/qt-3.3/lib
env:SERVICE_LIST=beeline cleardanglingscratchdir cli help hiveburninclient hiveserver2 hiveserver hwi jar lineage metastore metatool orcfiledump rcfilecat schemaTool version 
env:SHELL=/bin/bash
env:SHLVL=1
env:SPARK_HOME=/usr/hdp/2.6.0.3-8/spark
env:TERM=screen
env:USER=hive
env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
system:awt.toolkit=sun.awt.X11.XToolkit
system:file.encoding=UTF-8
system:file.encoding.pkg=sun.io
system:file.separator=/
system:hadoop.home.dir=/usr/hdp/2.6.0.3-8/hadoop
system:hadoop.id.str=hive
system:hadoop.log.dir=/var/log/hadoop/hive
system:hadoop.log.file=hadoop.log
system:hadoop.policy.file=hadoop-policy.xml
system:hadoop.root.logger=INFO,console
system:hadoop.security.logger=INFO,NullAppender
system:hdp.version=2.6.0.3-8
system:hive.aux.jars.path=file:///usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar
system:java.awt.graphicsenv=sun.awt.X11GraphicsEnvironment
system:java.awt.printerjob=sun.print.PSPrinterJob
system:java.class.path=:/hook/hive:/usr/hdp/2.6.0.3-8/atlas/hook/hive/hive-bridge-shim-0.8.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/atlas/hook/hive/atlas-plugin-classloader-0.8.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/hcatalog/hive-hcatalog-core-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/hcatalog/hive-hcatalog-server-extensions-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive-hcatalog/share/webhcat/java-client/hive-webhcat-java-client-1.2.1000.2.6.0.3-8.jar:/usr/hdp/current/hive-client/conf:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-core-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-fate-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-start-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/accumulo-trace-1.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/activation-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/ant-1.9.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/ant-launcher-1.9.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/antlr-2.7.7.jar:/usr/hdp/2.6.0.3-8/hive/lib/antlr-runtime-3.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/apache-log4j-extras-1.2.17.jar:/usr/hdp/2.6.0.3-8/hive/lib/asm-commons-3.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/asm-tree-3.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/avatica-1.8.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/avatica-metrics-1.8.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/avro-1.7.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/bonecp-0.8.0.RELEASE.jar:/usr/hdp/2.6.0.3-8/hive/lib/calcite-core-1.2.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/calcite-linq4j-1.2.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-cli-1.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-codec-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-collections-3.2.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-compiler-2.7.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-compress-1.4.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-dbcp-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-httpclient-3.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-lang-2.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-logging-1.1.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-math-2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-pool-1.5.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/commons-vfs2-2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-client-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-framework-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-api-jdo-4.2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-core-4.1.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/datanucleus-rdbms-4.1.7.jar:/usr/hdp/2.6.0.3-8/hive/lib/derby-10.10.2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/eigenbase-properties-1.1.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-annotation_1.0_spec-1.1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-jaspic_1.0_spec-1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/geronimo-jta_1.1_spec-1.1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/groovy-all-2.4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/guava-14.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/HikariCP-2.5.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-accumulo-handler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-accumulo-handler.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-ant-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-ant.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-beeline-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-beeline.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-cli-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-cli.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-common-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-common.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-contrib-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-contrib.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-exec-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-exec.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hbase-handler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hbase-handler.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hwi-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-hwi.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-jdbc-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-jdbc.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-metastore-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-metastore.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-serde-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-serde.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-service-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-service.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-0.20S-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-0.23-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-common-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-common.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-scheduler-1.2.1000.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/hive-shims-scheduler.jar:/usr/hdp/2.6.0.3-8/hive/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hive/lib/httpclient-4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/httpcore-4.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/ivy-2.4.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-annotations-2.4.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-core-2.4.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/jackson-databind-2.4.2.jar:/usr/hdp/2.6.0.3-8/hive/lib/janino-2.7.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/javax.jdo-3.2.0-m3.jar:/usr/hdp/2.6.0.3-8/hive/lib/jcommander-1.32.jar:/usr/hdp/2.6.0.3-8/hive/lib/jdo-api-3.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/jetty-all-7.6.0.v20120127.jar:/usr/hdp/2.6.0.3-8/hive/lib/jetty-all-server-7.6.0.v20120127.jar:/usr/hdp/2.6.0.3-8/hive/lib/jline-2.12.jar:/usr/hdp/2.6.0.3-8/hive/lib/joda-time-2.8.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/jpam-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/json-20090211.jar:/usr/hdp/2.6.0.3-8/hive/lib/jsr305-3.0.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/jta-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/libfb303-0.9.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/libthrift-0.9.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/log4j-1.2.16.jar:/usr/hdp/2.6.0.3-8/hive/lib/mail-1.4.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-api-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-provider-svn-commons-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/maven-scm-provider-svnexe-1.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-core-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-json-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/metrics-jvm-3.1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/mysql-connector-java.jar:/usr/hdp/2.6.0.3-8/hive/lib/netty-3.7.0.Final.jar:/usr/hdp/2.6.0.3-8/hive/lib/ojdbc6.jar:/usr/hdp/2.6.0.3-8/hive/lib/opencsv-2.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/oro-2.0.8.jar:/usr/hdp/2.6.0.3-8/hive/lib/paranamer-2.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/parquet-hadoop-bundle-1.8.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/usr/hdp/2.6.0.3-8/hive/lib/plexus-utils-1.5.6.jar:/usr/hdp/2.6.0.3-8/hive/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/ranger-hive-plugin-shim-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/ranger-plugin-classloader-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hive/lib/regexp-1.3.jar:/usr/hdp/2.6.0.3-8/hive/lib/servlet-api-2.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/snappy-java-1.0.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/ST4-4.0.4.jar:/usr/hdp/2.6.0.3-8/hive/lib/stax-api-1.0.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/stringtemplate-3.2.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/super-csv-2.2.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/transaction-api-1.1.jar:/usr/hdp/2.6.0.3-8/hive/lib/velocity-1.5.jar:/usr/hdp/2.6.0.3-8/hive/lib/xz-1.0.jar:/usr/hdp/2.6.0.3-8/hive/lib/zookeeper-3.4.6.2.6.0.3-8.jar::/usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar:/etc/hbase/conf:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-common-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-client-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-hadoop-compat-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-server-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hbase/lib/hbase-protocol-1.1.2.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hbase/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.6.0.3-8/hbase/lib/metrics-core-2.2.0.jar:jdbc-mysql.jar:mysql-connector-java-5.1.17.jar:mysql-connector-java-5.1.37.jar:mysql-connector-java.jar:/usr/hdp/2.6.0.3-8/hadoop/conf:/usr/hdp/2.6.0.3-8/hadoop/lib/azure-storage-4.2.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/activation-1.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/xz-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/nimbus-jose-jwt-3.9.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jsch-0.1.54.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jcip-annotations-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-collections-3.2.2.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/zookeeper-3.4.6.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/httpcore-4.4.4.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/azure-keyvault-core-0.8.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-lang3-3.4.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/curator-framework-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/json-smart-1.1.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/curator-client-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/ranger-plugin-classloader-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/slf4j-log4j12-1.7.10.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/joda-time-2.9.4.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/ojdbc6.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/ranger-yarn-plugin-shim-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jetty-sslengine-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/slf4j-api-1.7.10.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/ranger-hdfs-plugin-shim-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/junit-4.11.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/aws-java-sdk-core-1.10.6.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/httpclient-4.5.2.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/asm-3.2.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/jsr305-3.0.0.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/aws-java-sdk-kms-1.10.6.jar:/usr/hdp/2.6.0.3-8/hadoop/lib/aws-java-sdk-s3-1.10.6.jar:/usr/hdp/2.6.0.3-8/hadoop/.//azure-data-lake-store-sdk-2.1.4.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-annotations-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-aws.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-common.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-auth-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-azure-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-aws-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-azure-datalake-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-azure-datalake.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-nfs-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-common-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-common-2.7.3.2.6.0.3-8-tests.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-auth.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.6.0.3-8/hadoop/.//hadoop-azure.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/./:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/okhttp-2.4.0.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/okio-1.4.0.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jackson-core-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/lib/jsr305-3.0.0.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/.//hadoop-hdfs-nfs-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/.//hadoop-hdfs-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/.//hadoop-hdfs-2.7.3.2.6.0.3-8-tests.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.6.0.3-8/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/azure-storage-4.2.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/nimbus-jose-jwt-3.9.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jsch-0.1.54.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/curator-recipes-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jcip-annotations-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/zookeeper-3.4.6.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/httpcore-4.4.4.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jackson-databind-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jackson-annotations-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/azure-keyvault-core-0.8.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-lang3-3.4.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/curator-framework-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/json-smart-1.1.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/curator-client-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/javassist-3.18.1-GA.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/metrics-core-3.0.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/zookeeper-3.4.6.2.6.0.3-8-tests.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jetty-sslengine-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/httpclient-4.5.2.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/objenesis-2.1.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/jsr305-3.0.0.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/lib/fst-2.24.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-client-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-registry-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-api-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-common-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-common-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-sharedcachemanager-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-timeline-pluginstorage.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-tests-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.6.0.3-8/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//okhttp-2.4.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//okio-1.4.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//nimbus-jose-jwt-3.9.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jsch-0.1.54.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//curator-recipes-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jcip-annotations-1.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//zookeeper-3.4.6.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//httpcore-4.4.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//azure-keyvault-core-0.8.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-lang3-3.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//curator-framework-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//json-smart-1.1.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//curator-client-2.7.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//htrace-core-3.1.0-incubating.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-ant-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-datajoin-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-openstack-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-distcp-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-auth-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-gridmix-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-sls-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-streaming-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-openstack.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jetty-sslengine-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-rumen-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//httpclient-4.5.2.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//jsr305-3.0.0.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-extras-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.7.3.2.6.0.3-8-tests.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-archives-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-yarn-timeline-history-with-fs-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-common-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-runtime-internals-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-history-parser-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-job-analyzer-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-runtime-library-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-yarn-timeline-cache-plugin-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-dag-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-tests-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-yarn-timeline-history-with-acls-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-yarn-timeline-history-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-examples-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-api-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/tez-mapreduce-0.7.0.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/tez/lib/hadoop-annotations-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.6.0.3-8/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.6.0.3-8/tez/lib/commons-collections-3.2.2.jar:/usr/hdp/2.6.0.3-8/tez/lib/jersey-json-1.9.jar:/usr/hdp/2.6.0.3-8/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.6.0.3-8/tez/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.6.0.3-8/tez/lib/guava-11.0.2.jar:/usr/hdp/2.6.0.3-8/tez/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.6.0.3-8/tez/lib/servlet-api-2.5.jar:/usr/hdp/2.6.0.3-8/tez/lib/commons-io-2.4.jar:/usr/hdp/2.6.0.3-8/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.6.0.3-8/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.6.0.3-8/tez/lib/azure-data-lake-store-sdk-2.1.4.jar:/usr/hdp/2.6.0.3-8/tez/lib/hadoop-yarn-server-web-proxy-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/metrics-core-3.1.0.jar:/usr/hdp/2.6.0.3-8/tez/lib/hadoop-yarn-server-timeline-pluginstorage-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/jersey-client-1.9.jar:/usr/hdp/2.6.0.3-8/tez/lib/hadoop-azure-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/hadoop-aws-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/hadoop-azure-datalake-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.6.0.3-8/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.6.0.3-8/tez/lib/hadoop-mapreduce-client-core-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/hadoop-mapreduce-client-common-2.7.3.2.6.0.3-8.jar:/usr/hdp/2.6.0.3-8/tez/lib/commons-collections4-4.1.jar:/usr/hdp/2.6.0.3-8/tez/conf
system:java.class.version=52.0
system:java.endorsed.dirs=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/endorsed
system:java.ext.dirs=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/ext:/usr/java/packages/lib/ext
system:java.home=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre
system:java.io.tmpdir=/tmp
system:java.library.path=:/usr/hdp/2.6.0.3-8/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.6.0.3-8/hadoop/lib/native
system:java.net.preferIPv4Stack=true
system:java.runtime.name=OpenJDK Runtime Environment
system:java.runtime.version=1.8.0_131-b11
system:java.specification.name=Java Platform API Specification
system:java.specification.vendor=Oracle Corporation
system:java.specification.version=1.8
system:java.util.logging.config.file=/usr/hdp/current/hive-client/conf/parquet-logging.properties
system:java.vendor=Oracle Corporation
system:java.vendor.url=http://java.oracle.com/
system:java.vendor.url.bug=http://bugreport.sun.com/bugreport/
system:java.version=1.8.0_131
system:java.vm.info=mixed mode
system:java.vm.name=OpenJDK 64-Bit Server VM
system:java.vm.specification.name=Java Virtual Machine Specification
system:java.vm.specification.vendor=Oracle Corporation
system:java.vm.specification.version=1.8
system:java.vm.vendor=Oracle Corporation
system:java.vm.version=25.131-b11
system:line.separator=

system:os.arch=amd64
system:os.name=Linux
system:os.version=4.4.0-72-generic
system:path.separator=:
system:sun.arch.data.model=64
system:sun.boot.class.path=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/resources.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/rt.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/jsse.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/jce.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/charsets.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/jfr.jar:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/classes
system:sun.boot.library.path=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-0.b11.el6_9.x86_64/jre/lib/amd64
system:sun.cpu.endian=little
system:sun.cpu.isalist=
system:sun.io.unicode.encoding=UnicodeLittle
system:sun.java.command=org.apache.hadoop.util.RunJar /usr/hdp/2.6.0.3-8/hive/lib/hive-cli-1.2.1000.2.6.0.3-8.jar org.apache.hadoop.hive.cli.CliDriver --hiveconf hive.aux.jars.path=file:///usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar -e set -v
system:sun.java.launcher=SUN_STANDARD
system:sun.jnu.encoding=UTF-8
system:sun.management.compiler=HotSpot 64-Bit Tiered Compilers
system:sun.os.patch.level=unknown
system:user.country=US
system:user.dir=/home/hive
system:user.home=/home/hive
system:user.language=en
system:user.name=hive
system:user.timezone=Etc/UTC
